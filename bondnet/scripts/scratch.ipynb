{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import time \n",
    "import numpy as np \n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from bondnet.data.dataset import ReactionNetworkDataset\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.featurizer import AtomFeaturizerMinimum, AtomFeaturizerFull, BondAsNodeFeaturizerMinimum, GlobalFeaturizer, BondAsNodeFeaturizerFull\n",
    "from bondnet.data.grapher import HeteroMoleculeGraph\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork\n",
    "from bondnet.scripts.create_label_file import read_input_files\n",
    "from bondnet.model.metric import WeightedL1Loss\n",
    "from bondnet.prediction.load_model import load_dataset, load_model\n",
    "from bondnet.utils import seed_torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def train(optimizer, model, nodes, data_loader, loss_fn, metric_fn):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    count = 0.0\n",
    "\n",
    "    for it, (batched_graph, label) in enumerate(data_loader):\n",
    "        feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "        target = label[\"value\"]\n",
    "        stdev = label[\"scaler_stdev\"]\n",
    "\n",
    "        pred = model(batched_graph, feats, label[\"reaction\"])\n",
    "        pred = pred.view(-1)\n",
    "\n",
    "        loss = loss_fn(pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() # here is the actual optimizer step\n",
    "\n",
    "        epoch_loss += loss.detach().item()\n",
    "        accuracy += metric_fn(pred, target, stdev).detach().item()\n",
    "        count += len(target)\n",
    "    \n",
    "    epoch_loss /= it + 1\n",
    "    accuracy /= count\n",
    "\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def evaluate(model, nodes, data_loader, metric_fn):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        accuracy = 0.0\n",
    "        count = 0.0\n",
    "\n",
    "        for batched_graph, label in data_loader:\n",
    "            feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "            target = label[\"value\"]\n",
    "            stdev = label[\"scaler_stdev\"]\n",
    "\n",
    "            pred = model(batched_graph, feats, label[\"reaction\"])\n",
    "            pred = pred.view(-1)\n",
    "\n",
    "            accuracy += metric_fn(pred, target, stdev).detach().item()\n",
    "            count += len(target)\n",
    "\n",
    "    return accuracy / count\n",
    "\n",
    "def get_grapher():\n",
    "    atom_featurizer = AtomFeaturizerMinimum()\n",
    "    bond_featurizer = BondAsNodeFeaturizerMinimum()\n",
    "    #bond_featurizer = BondAsNodeFeaturizerFull()\n",
    "    # our example dataset contains molecules of charges -1, 0, and 1\n",
    "    global_featurizer = GlobalFeaturizer(allowed_charges=[-2, -1, 0, 1, 2])\n",
    "\n",
    "    grapher = HeteroMoleculeGraph(atom_featurizer, bond_featurizer, global_featurizer)\n",
    "    \n",
    "    return grapher\n",
    "\n",
    "def parse_settings(file = \"./input_files/input_1.txt\"):\n",
    "\n",
    "    #some default values that get written over if in the file\n",
    "    test = True\n",
    "    epochs = 10\n",
    "    embedding_size = 24\n",
    "    \n",
    "    fc_hidden_size = [128, 64]\n",
    "    fc_layers = -1\n",
    "    fc_activation = \"ReLU\"\n",
    "    fc_batch_norm = 0\n",
    "    fc_dropout = 0.0\n",
    "\n",
    "    gated_hidden_size = [64, 64, 64]\n",
    "    gated_layers = -1\n",
    "    gated_batch_norm = 0\n",
    "    gated_graph_norm = 0\n",
    "    gated_dropout = 0.0\n",
    "    gated_activation = 'ReLU'\n",
    "\n",
    "    num_lstm_layers = 3\n",
    "    num_lstm_iters = 5\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(file) as f:\n",
    "        lines =  f.readlines()\n",
    "    \n",
    "        for i in lines: \n",
    "            if(len(i.split()) > 1):\n",
    "                if(i.split()[0] == 'test'):\n",
    "                    test = bool(i.split()[1])\n",
    "                if(i.split()[0] == 'epochs'):\n",
    "                    epochs = int(i.split()[1])\n",
    "                if(i.split()[0] == 'embedding_size'):\n",
    "                    embedding_size = int(i.split()[1])\n",
    "\n",
    "                if(i.split()[0] == 'gated_hidden_size'):\n",
    "                    gated_hidden_size = [int(j) for j in i.split()[1:]]\n",
    "                if(i.split()[0] == 'gated_layers'):\n",
    "                    gated_layers = int(i.split()[1])\n",
    "                if(i.split()[0] == 'gated_dropout'):\n",
    "                    gated_dropout = float(i.split()[1])\n",
    "                if(i.split()[0] == 'gated_graph_norm'):\n",
    "                    gated_graph_norm = int(i.split()[1])\n",
    "                if(i.split()[0] == 'gated_batch_norm'):\n",
    "                    gated_batch_norm = int(i.split()[1])\n",
    "                if(i.split()[0] == 'gated_activation'):\n",
    "                    gated_activation = str(i.split()[1])\n",
    "\n",
    "                if(i.split()[0] == 'fc_hidden_size'):\n",
    "                    fc_hidden_size = [int(j) for j in i.split()[1:]]\n",
    "                if(i.split()[0] == 'fc_layers'):\n",
    "                    fc_layers = int(i.split()[1])\n",
    "                if(i.split()[0] == 'fc_activation'):\n",
    "                    fc_activation = str(i.split()[1])\n",
    "                if(i.split()[0] == 'fc_batch_norm'):\n",
    "                    fc_batch_norm = int(i.split()[1])\n",
    "                if(i.split()[0] == 'fc_dropout'):\n",
    "                    fc_dropout = float(i.split()[1])\n",
    "\n",
    "                if(i.split()[0] == 'num_lstm_iters'):\n",
    "                    num_lstm_iters = int(i.split()[1])\n",
    "                if(i.split()[0] == 'num_lstm_layers'):\n",
    "                    num_lstm_layers = int(i.split()[1])\n",
    "\n",
    "        if(gated_layers == -1):\n",
    "            gated_layers = len(gated_hidden_size)\n",
    "        if(fc_layers == -1):\n",
    "            fc_layers = len(fc_hidden_size)\n",
    "\n",
    "        print(\"using the following settings:\")\n",
    "        print(\"--\" * 20)\n",
    "\n",
    "        print(\"epochs: {:1d}\".format(epochs))\n",
    "        print(\"Small Dataset?: \" + str(test))\n",
    "        print(\"embedding size: {:1d}\".format(embedding_size))\n",
    "        \n",
    "        print(\"fc layers: {:1d}\".format(fc_layers))\n",
    "        print(\"fc hidden layer: \" + str(fc_hidden_size))\n",
    "        print(\"fc activation: \" + str(fc_activation))\n",
    "        print(\"fc batch norm: \" + str(fc_batch_norm))\n",
    "        print(\"fc dropout: {:.2f}\".format(fc_dropout))\n",
    "\n",
    "        print(\"gated layers: {:1d}\".format(gated_layers))\n",
    "        print(\"gated hidden layers: \" + str(gated_hidden_size))\n",
    "        print(\"gated activation: \" + str(gated_activation))\n",
    "        print(\"gated dropout: {:.2f}\".format(gated_dropout))\n",
    "        print(\"gated batch norm: \" + str(gated_batch_norm))\n",
    "        print(\"gated graph norm: \" + str(gated_graph_norm))\n",
    "\n",
    "        print(\"num lstm iters: \" + str(num_lstm_iters))\n",
    "        print(\"num lstm layer: \" + str(num_lstm_layers))\n",
    "        print(\"--\" * 20)\n",
    "\n",
    "        dict_ret = {}\n",
    "        dict_ret[\"test\"] = test\n",
    "        dict_ret[\"epochs\"] = epochs\n",
    "        dict_ret[\"embedding_size\"] = embedding_size\n",
    "        \n",
    "        dict_ret[\"fc_hidden_size\"] = fc_hidden_size\n",
    "        dict_ret[\"fc_layers\"] = fc_layers\n",
    "        dict_ret['fc_dropout'] = fc_dropout\n",
    "        dict_ret['fc_batch_norm'] = fc_batch_norm\n",
    "        dict_ret['fc_activation'] = fc_activation\n",
    "\n",
    "        dict_ret[\"gated_hidden_size\"] = gated_hidden_size\n",
    "        dict_ret[\"gated_layers\"] = gated_layers\n",
    "        dict_ret[\"gated_activation\"] = gated_activation\n",
    "        dict_ret[\"gated_graph_norm\"] = gated_graph_norm\n",
    "        dict_ret[\"gated_batch_norm\"] = gated_batch_norm\n",
    "        dict_ret['gated_dropout'] = gated_dropout\n",
    "        \n",
    "        dict_ret[\"num_lstm_iters\"] = num_lstm_iters\n",
    "        dict_ret[\"num_lstm_layers\"] = num_lstm_layers\n",
    "        \n",
    "        return dict_ret \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the following settings:\n",
      "----------------------------------------\n",
      "restore: True\n",
      "distributed: False\n",
      "batch size: 100\n",
      "on gpu: False\n",
      "epochs: 1000\n",
      "embedding size: 24\n",
      "fc layers: 2\n",
      "fc hidden layer: [384, 192]\n",
      "gated layers: 4\n",
      "gated hidden layers: [192, 192, 192, 192]\n",
      "gated fc layers: 2\n",
      "num lstm iters: 6\n",
      "num lstm layer: 3\n",
      "num gpu: 1\n",
      "hyperparam save file: ./hyper.pkl\n",
      "dataset state dict: home/santiagovargas/Documents/Dataset/mg/dataset_state_dict.pkl\n",
      "model dir/home/santiagovargas/Documents/Dataset/mg/\n",
      "Small Dataset?: False\n",
      "lr: 0.001000\n",
      "weight decay: 0.000\n",
      "fc activation: ReLU\n",
      "fc batch norm: 0\n",
      "fc dropout: 0.00\n",
      "gated activation: ReLU\n",
      "gated dropout: 0.10\n",
      "gated batch norm: True\n",
      "gated graph norm: 0\n",
      "gated resid: True\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): GatedGCNConv(\n",
       "    (activation): ReLU()\n",
       "    (A): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (B): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (C): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (D): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (E): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (F): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (G): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (H): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (I): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bn_node_h): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_e): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_u): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (1): GatedGCNConv(\n",
       "    (activation): ReLU()\n",
       "    (A): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (B): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (C): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (D): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (E): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (F): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (G): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (H): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (I): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bn_node_h): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_e): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_u): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (2): GatedGCNConv(\n",
       "    (activation): ReLU()\n",
       "    (A): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (B): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (C): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (D): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (E): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (F): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (G): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (H): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (I): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bn_node_h): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_e): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_u): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (3): GatedGCNConv(\n",
       "    (activation): ReLU()\n",
       "    (A): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (B): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (C): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (D): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (E): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (F): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (G): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (H): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (I): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bn_node_h): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_e): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_u): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bondnet.utils import parse_settings\n",
    "dict_ret = parse_settings(file='./input_files/input_2.txt')\n",
    "model = load_model(dict_ret['model_path'])\n",
    "model.gated_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheesh\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model trained with a dataset having species: C,F,H,Mg,N,O,S; Cannot make predictions for molecule containing species: Li. Note that two models trained on different datasets are provided: the `pubchem` supports C, H, O, N and the `bdncm` supports C, H, O, F, Li. You may want to switch the model if you see this message.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79646/74992533.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmolecules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     extra_features=attrs)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bondnet/bondnet/prediction/load_model.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(model_path, molecules, labels, extra_features)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mstate_dict_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset_state_dict.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0m_check_species\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolecules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0m_check_charge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bondnet/bondnet/prediction/load_model.py\u001b[0m in \u001b[0;36m_check_species\u001b[0;34m(molecules, state_dict_filename)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0msupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_species\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         raise ValueError(\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0;34mf\"Model trained with a dataset having species: {supported}; Cannot make \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;34mf\"predictions for molecule containing species: {not_supported}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;34mf\"Note that two models trained on different datasets are provided: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Model trained with a dataset having species: C,F,H,Mg,N,O,S; Cannot make predictions for molecule containing species: Li. Note that two models trained on different datasets are provided: the `pubchem` supports C, H, O, N and the `bdncm` supports C, H, O, F, Li. You may want to switch the model if you see this message."
     ]
    }
   ],
   "source": [
    "if(bool(dict_ret[\"test\"])):\n",
    "    mols, attrs, labels = read_input_files(\n",
    "        'examples/train/molecules.sdf', \n",
    "        'examples/train/molecule_attributes.yaml', \n",
    "        'examples/train/reactions.yaml', \n",
    "    )\n",
    "else:\n",
    "    # todo \n",
    "    #mols, attrs, labels = read_input_files(\n",
    "    #    'examples/train/molecules_libe.sdf', \n",
    "    #    'examples/train/molecule_attributes_libe.yaml', \n",
    "    #    'examples/train/reactions_libe.yaml', \n",
    "    #)\n",
    "        \n",
    "    # todo\n",
    "    #mols_mg, attrs_mg, labels_mg = read_input_files(\n",
    "    #    '../train/molecules_libe.sdf', \n",
    "    #    '../train/train/molecule_attributes_libe.yaml', \n",
    "    #    '../train/train/reactions_libe.yaml', \n",
    "    #)\n",
    "\n",
    "    mols, attrs, labels = read_input_files(\n",
    "        'examples/train/molecules.sdf', \n",
    "        'examples/train/molecule_attributes.yaml', \n",
    "        'examples/train/reactions.yaml', \n",
    "    )\n",
    "    \n",
    "    print(\"sheesh\")\n",
    "    #mols, attrs , labels = read_input_files()\n",
    "\n",
    "\n",
    "#dataset = ReactionNetworkDataset(\n",
    "#    grapher=get_grapher(),\n",
    "#    molecules=mols,\n",
    "#    labels=labels,\n",
    "#    extra_features=attrs\n",
    "#)\n",
    "#def load_dataset(model_path, molecules, labels, extra_features):\n",
    "model = load_model(dict_ret['model_path'])\n",
    "dataset = load_dataset(\n",
    "    dict_ret[\"model_path\"],\n",
    "    molecules=mols,\n",
    "    labels=labels,\n",
    "    extra_features=attrs)\n",
    "\n",
    "\n",
    "trainset, valset, testset = train_validation_test_split(dataset, validation=0.1, test=0.1)\n",
    "\n",
    "# we train with a batch size of 100\n",
    "train_loader = DataLoaderReactionNetwork(trainset, batch_size=100,shuffle=True)\n",
    "val_loader = DataLoaderReactionNetwork(valset, batch_size=len(valset), shuffle=False)\n",
    "test_loader = DataLoaderReactionNetwork(testset, batch_size=len(testset), shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_features: 15, 7, 9\n",
      "{'atom': 13, 'bond': 7, 'global': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"required_features: 15, 7, 9\")\n",
    "print(dataset.feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch     Loss         TrainAcc        ValAcc\n",
      "    0   8.354622e-01   2.457747e+00   2.090321e+00\n",
      "    5   5.997426e-01   2.131326e+00   1.854207e+00\n",
      "   10   3.939752e-01   1.736316e+00   1.741784e+00\n",
      "   15   4.004955e-01   1.777406e+00   1.947630e+00\n",
      "   20   3.577470e-01   1.632960e+00   1.456190e+00\n",
      "   25   2.316015e-01   1.361877e+00   1.209444e+00\n",
      "   30   2.086340e-01   1.235057e+00   1.274223e+00\n",
      "   35   2.070761e-01   1.257603e+00   1.237815e+00\n",
      "   40   1.872679e-01   1.174746e+00   1.171825e+00\n",
      "   45   1.694346e-01   1.121845e+00   1.209740e+00\n",
      "   50   1.505942e-01   1.087599e+00   1.227573e+00\n",
      "   55   1.248520e-01   1.002119e+00   1.212870e+00\n",
      "   60   1.600399e-01   1.060676e+00   1.172067e+00\n",
      "   65   1.364062e-01   1.022181e+00   1.232711e+00\n",
      "   70   1.377577e-01   1.037374e+00   1.191099e+00\n",
      "   75   1.240184e-01   9.555707e-01   1.293485e+00\n",
      "   80   1.012025e-01   8.473748e-01   1.273484e+00\n",
      "   85   9.228709e-02   8.663695e-01   1.098703e+00\n",
      "   90   7.441843e-02   7.834238e-01   1.040848e+00\n",
      "   95   7.522986e-02   7.631644e-01   1.032907e+00\n",
      "  100   6.878521e-02   7.609694e-01   1.077767e+00\n",
      "  105   7.537310e-02   7.894107e-01   1.034274e+00\n",
      "  110   7.667498e-02   7.767191e-01   1.067675e+00\n",
      "  115   7.484786e-02   7.363903e-01   1.091353e+00\n",
      "  120   6.422543e-02   7.039043e-01   1.234220e+00\n",
      "  125   8.075837e-02   7.682405e-01   1.058505e+00\n",
      "  130   6.263306e-02   6.846303e-01   1.048112e+00\n",
      "  135   7.054856e-02   6.666646e-01   9.010829e-01\n",
      "  140   5.400955e-02   6.341265e-01   9.818805e-01\n",
      "  145   6.545419e-02   6.792798e-01   1.031975e+00\n",
      "  150   6.300042e-02   6.633443e-01   1.114793e+00\n",
      "  155   5.747807e-02   6.613629e-01   1.197821e+00\n",
      "  160   6.766270e-02   7.292619e-01   1.109440e+00\n",
      "  165   7.155528e-02   6.466055e-01   1.062312e+00\n",
      "  170   5.606647e-02   6.650330e-01   9.975495e-01\n",
      "  175   5.539288e-02   6.385573e-01   9.832197e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54216/3889286270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# train on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size, \n",
    "    embedding_size=dict_ret[\"embedding_size\"],\n",
    "    gated_num_layers=dict_ret[\"gated_num_layers\"],\n",
    "    gated_hidden_size=dict_ret[\"gated_hidden_size\"],\n",
    "    gated_activation=dict_ret[\"gated_activation\"],\n",
    "    gated_dropout=float(dict_ret[\"gated_dropout\"]),\n",
    "    gated_graph_norm=int(dict_ret[\"gated_graph_norm\"]),\n",
    "    gated_batch_norm=int(dict_ret[\"gated_batch_norm\"]),\n",
    "    fc_num_layers=dict_ret[\"fc_layers\"],\n",
    "    fc_hidden_size=dict_ret[\"fc_hidden_size\"],\n",
    "    fc_activation=dict_ret[\"fc_activation\"],\n",
    "    fc_dropout=float(dict_ret[\"fc_dropout\"]),\n",
    "    fc_batch_norm=int(dict_ret[\"fc_batch_norm\"]),\n",
    "    num_lstm_iters=dict_ret[\"num_lstm_iters\"],\n",
    "    num_lstm_layers=dict_ret[\"num_lstm_layers\"],\n",
    "    conv=\"GatedGCNConv\"\n",
    ")\n",
    "\n",
    "# optimizer, loss function and metric function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = MSELoss(reduction=\"mean\")\n",
    "metric = WeightedL1Loss(reduction=\"sum\")\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "best = 1e10\n",
    "\n",
    "# main training loop\n",
    "print(\"# Epoch     Loss         TrainAcc        ValAcc\")\n",
    "t1 = time.time()\n",
    "\n",
    "for epoch in range(dict_ret[\"epochs\"]):\n",
    "    if(epoch % 5 == 0):\n",
    "\n",
    "        # train on training set \n",
    "        loss, train_acc = train( optimizer, model, feature_names, train_loader, loss_func, metric)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_acc = evaluate(model, feature_names, val_loader, metric)\n",
    "\n",
    "        # save checkpoint for best performing model \n",
    "        if (val_acc < best):\n",
    "            best = val_acc\n",
    "            torch.save(model.state_dict(), 'checkpoint.pkl')\n",
    "        \n",
    "        print(\"{:5d}   {:12.6e}   {:12.6e}   {:12.6e}\".format(epoch, loss, train_acc, val_acc))\n",
    "t2 = time.time()\n",
    "\n",
    "\n",
    "# load best performing model and test it's performance on the test set\n",
    "checkpoint = torch.load(\"checkpoint.pkl\")\n",
    "model.load_state_dict(checkpoint)\n",
    "test_acc = evaluate(model, feature_names, test_loader, metric)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])    \n",
    "\n",
    "print(\"TestAcc: {:12.6e}\".format(test_acc))\n",
    "print(\"Time to Train: {:5.1f} seconds\".format(float(t2 - t1)))\n",
    "print(\"Number of Trainable Model Params: {}\".format(params))\n",
    "\n",
    "\n",
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=dict_ret[\"embedding_size\"],\n",
    "    gated_num_layers=dict_ret[\"gated_num_layers\"],\n",
    "    gated_hidden_size=dict_ret[\"gated_hidden_size\"],\n",
    "    gated_activation=dict_ret[\"gated_activation\"],\n",
    "    gated_dropout=float(dict_ret[\"gated_dropout\"]),\n",
    "    gated_graph_norm=int(dict_ret[\"gated_graph_norm\"]),\n",
    "    gated_batch_norm=int(dict_ret[\"gated_batch_norm\"]),\n",
    "    gated_residual=dict_ret[\"gated_residual\"],\n",
    "    gated_num_fc_layers=dict_ret[\"gated_num_fc_layers\"],\n",
    "    fc_num_layers=dict_ret[\"fc_layers\"],\n",
    "    fc_hidden_size=dict_ret[\"fc_hidden_size\"],\n",
    "    fc_activation=dict_ret[\"fc_activation\"],\n",
    "    fc_dropout=float(dict_ret[\"fc_dropout\"]),\n",
    "    fc_batch_norm=int(dict_ret[\"fc_batch_norm\"]),\n",
    "    num_lstm_iters=dict_ret[\"num_lstm_iters\"],\n",
    "    num_lstm_layers=dict_ret[\"num_lstm_layers\"],\n",
    "    conv=\"GatedGCNConv\",\n",
    ")\n",
    "\n",
    "print(\"-\" * 20 + \"now disabling gradients\" + \"-\" * 20)\n",
    "model.gated_layers.requires_grad_(False)\n",
    "\n",
    "#model.fc_layers.requires_grad_(False)\n",
    "#model.readout_layer.requires_grad_(False)\n",
    "\n",
    "\n",
    "best = 1e10\n",
    "\n",
    "# main training loop\n",
    "print(\"# Epoch     Loss         TrainAcc        ValAcc\")\n",
    "t1 = time.time()\n",
    "\n",
    "for epoch in range(dict_ret[\"epochs\"]):\n",
    "    if(epoch % 5 == 0):\n",
    "        # train on training set \n",
    "        loss, train_acc = train( optimizer, model, feature_names, train_loader, loss_func, metric)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_acc = evaluate(model, feature_names, val_loader, metric)\n",
    "\n",
    "        # save checkpoint for best performing model \n",
    "        \n",
    "        if (val_acc < best):\n",
    "            best = val_acc\n",
    "            torch.save(model.state_dict(), 'checkpoint.pkl')\n",
    "            \n",
    "        print(\"{:5d}   {:12.6e}   {:12.6e}   {:12.6e}\".format(epoch, loss, train_acc, val_acc))\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "\n",
    "# load best performing model and test it's performance on the test set\n",
    "from os.path import expanduser\n",
    "#home = expanduser(\"~\")\n",
    "#model_directory = home+\"/Documents/Dataset/mg/checkpoint.pkl\" \n",
    "\n",
    "#checkpoint = torch.load(model_directory)\n",
    "#model.load_state_dict(checkpoint['model'])\n",
    "#test_acc = evaluate(model, feature_names, test_loader, metric)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])    \n",
    "\n",
    "print(\"TestAcc: {:12.6e}\".format(test_acc))\n",
    "print(\"Time to Train: {:5.1f} seconds\".format(float(t2 - t1)))\n",
    "print(\"Number of Trainable Model Params: {}\".format(params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------now disabling gradients--------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GatedGCNReactionNetwork:\n\tMissing key(s) in state_dict: \"gated_layers.3.A.fc_layers.0.weight\", \"gated_layers.3.A.fc_layers.0.bias\", \"gated_layers.3.A.fc_layers.2.weight\", \"gated_layers.3.A.fc_layers.2.bias\", \"gated_layers.3.B.fc_layers.0.weight\", \"gated_layers.3.B.fc_layers.0.bias\", \"gated_layers.3.B.fc_layers.2.weight\", \"gated_layers.3.B.fc_layers.2.bias\", \"gated_layers.3.C.fc_layers.0.weight\", \"gated_layers.3.C.fc_layers.0.bias\", \"gated_layers.3.C.fc_layers.2.weight\", \"gated_layers.3.C.fc_layers.2.bias\", \"gated_layers.3.D.fc_layers.0.weight\", \"gated_layers.3.D.fc_layers.0.bias\", \"gated_layers.3.D.fc_layers.2.weight\", \"gated_layers.3.D.fc_layers.2.bias\", \"gated_layers.3.E.fc_layers.0.weight\", \"gated_layers.3.E.fc_layers.0.bias\", \"gated_layers.3.E.fc_layers.2.weight\", \"gated_layers.3.E.fc_layers.2.bias\", \"gated_layers.3.F.fc_layers.0.weight\", \"gated_layers.3.F.fc_layers.0.bias\", \"gated_layers.3.F.fc_layers.2.weight\", \"gated_layers.3.F.fc_layers.2.bias\", \"gated_layers.3.G.fc_layers.0.weight\", \"gated_layers.3.G.fc_layers.0.bias\", \"gated_layers.3.G.fc_layers.2.weight\", \"gated_layers.3.G.fc_layers.2.bias\", \"gated_layers.3.H.fc_layers.0.weight\", \"gated_layers.3.H.fc_layers.0.bias\", \"gated_layers.3.H.fc_layers.2.weight\", \"gated_layers.3.H.fc_layers.2.bias\", \"gated_layers.3.I.fc_layers.0.weight\", \"gated_layers.3.I.fc_layers.0.bias\", \"gated_layers.3.I.fc_layers.2.weight\", \"gated_layers.3.I.fc_layers.2.bias\", \"gated_layers.3.bn_node_h.weight\", \"gated_layers.3.bn_node_h.bias\", \"gated_layers.3.bn_node_h.running_mean\", \"gated_layers.3.bn_node_h.running_var\", \"gated_layers.3.bn_node_e.weight\", \"gated_layers.3.bn_node_e.bias\", \"gated_layers.3.bn_node_e.running_mean\", \"gated_layers.3.bn_node_e.running_var\", \"gated_layers.3.bn_node_u.weight\", \"gated_layers.3.bn_node_u.bias\", \"gated_layers.3.bn_node_u.running_mean\", \"gated_layers.3.bn_node_u.running_var\", \"fc_layers.2.weight\", \"fc_layers.2.bias\". \n\tUnexpected key(s) in state_dict: \"readout_layer.layers.atom.lstm.weight_ih_l3\", \"readout_layer.layers.atom.lstm.weight_hh_l3\", \"readout_layer.layers.atom.lstm.bias_ih_l3\", \"readout_layer.layers.atom.lstm.bias_hh_l3\", \"readout_layer.layers.atom.lstm.weight_ih_l4\", \"readout_layer.layers.atom.lstm.weight_hh_l4\", \"readout_layer.layers.atom.lstm.bias_ih_l4\", \"readout_layer.layers.atom.lstm.bias_hh_l4\", \"readout_layer.layers.bond.lstm.weight_ih_l3\", \"readout_layer.layers.bond.lstm.weight_hh_l3\", \"readout_layer.layers.bond.lstm.bias_ih_l3\", \"readout_layer.layers.bond.lstm.bias_hh_l3\", \"readout_layer.layers.bond.lstm.weight_ih_l4\", \"readout_layer.layers.bond.lstm.weight_hh_l4\", \"readout_layer.layers.bond.lstm.bias_ih_l4\", \"readout_layer.layers.bond.lstm.bias_hh_l4\", \"fc_layers.6.weight\", \"fc_layers.6.bias\", \"fc_layers.1.weight\", \"fc_layers.1.bias\", \"fc_layers.1.running_mean\", \"fc_layers.1.running_var\", \"fc_layers.1.num_batches_tracked\", \"fc_layers.3.weight\", \"fc_layers.3.bias\", \"fc_layers.4.running_mean\", \"fc_layers.4.running_var\", \"fc_layers.4.num_batches_tracked\". \n\tsize mismatch for gated_layers.0.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l0: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l0: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for fc_layers.0.weight: copying a param with shape torch.Size([32, 320]) from checkpoint, the shape in current model is torch.Size([384, 960]).\n\tsize mismatch for fc_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for fc_layers.4.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1, 192]).\n\tsize mismatch for fc_layers.4.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24432/339809252.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoint.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1045\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GatedGCNReactionNetwork:\n\tMissing key(s) in state_dict: \"gated_layers.3.A.fc_layers.0.weight\", \"gated_layers.3.A.fc_layers.0.bias\", \"gated_layers.3.A.fc_layers.2.weight\", \"gated_layers.3.A.fc_layers.2.bias\", \"gated_layers.3.B.fc_layers.0.weight\", \"gated_layers.3.B.fc_layers.0.bias\", \"gated_layers.3.B.fc_layers.2.weight\", \"gated_layers.3.B.fc_layers.2.bias\", \"gated_layers.3.C.fc_layers.0.weight\", \"gated_layers.3.C.fc_layers.0.bias\", \"gated_layers.3.C.fc_layers.2.weight\", \"gated_layers.3.C.fc_layers.2.bias\", \"gated_layers.3.D.fc_layers.0.weight\", \"gated_layers.3.D.fc_layers.0.bias\", \"gated_layers.3.D.fc_layers.2.weight\", \"gated_layers.3.D.fc_layers.2.bias\", \"gated_layers.3.E.fc_layers.0.weight\", \"gated_layers.3.E.fc_layers.0.bias\", \"gated_layers.3.E.fc_layers.2.weight\", \"gated_layers.3.E.fc_layers.2.bias\", \"gated_layers.3.F.fc_layers.0.weight\", \"gated_layers.3.F.fc_layers.0.bias\", \"gated_layers.3.F.fc_layers.2.weight\", \"gated_layers.3.F.fc_layers.2.bias\", \"gated_layers.3.G.fc_layers.0.weight\", \"gated_layers.3.G.fc_layers.0.bias\", \"gated_layers.3.G.fc_layers.2.weight\", \"gated_layers.3.G.fc_layers.2.bias\", \"gated_layers.3.H.fc_layers.0.weight\", \"gated_layers.3.H.fc_layers.0.bias\", \"gated_layers.3.H.fc_layers.2.weight\", \"gated_layers.3.H.fc_layers.2.bias\", \"gated_layers.3.I.fc_layers.0.weight\", \"gated_layers.3.I.fc_layers.0.bias\", \"gated_layers.3.I.fc_layers.2.weight\", \"gated_layers.3.I.fc_layers.2.bias\", \"gated_layers.3.bn_node_h.weight\", \"gated_layers.3.bn_node_h.bias\", \"gated_layers.3.bn_node_h.running_mean\", \"gated_layers.3.bn_node_h.running_var\", \"gated_layers.3.bn_node_e.weight\", \"gated_layers.3.bn_node_e.bias\", \"gated_layers.3.bn_node_e.running_mean\", \"gated_layers.3.bn_node_e.running_var\", \"gated_layers.3.bn_node_u.weight\", \"gated_layers.3.bn_node_u.bias\", \"gated_layers.3.bn_node_u.running_mean\", \"gated_layers.3.bn_node_u.running_var\", \"fc_layers.2.weight\", \"fc_layers.2.bias\". \n\tUnexpected key(s) in state_dict: \"readout_layer.layers.atom.lstm.weight_ih_l3\", \"readout_layer.layers.atom.lstm.weight_hh_l3\", \"readout_layer.layers.atom.lstm.bias_ih_l3\", \"readout_layer.layers.atom.lstm.bias_hh_l3\", \"readout_layer.layers.atom.lstm.weight_ih_l4\", \"readout_layer.layers.atom.lstm.weight_hh_l4\", \"readout_layer.layers.atom.lstm.bias_ih_l4\", \"readout_layer.layers.atom.lstm.bias_hh_l4\", \"readout_layer.layers.bond.lstm.weight_ih_l3\", \"readout_layer.layers.bond.lstm.weight_hh_l3\", \"readout_layer.layers.bond.lstm.bias_ih_l3\", \"readout_layer.layers.bond.lstm.bias_hh_l3\", \"readout_layer.layers.bond.lstm.weight_ih_l4\", \"readout_layer.layers.bond.lstm.weight_hh_l4\", \"readout_layer.layers.bond.lstm.bias_ih_l4\", \"readout_layer.layers.bond.lstm.bias_hh_l4\", \"fc_layers.6.weight\", \"fc_layers.6.bias\", \"fc_layers.1.weight\", \"fc_layers.1.bias\", \"fc_layers.1.running_mean\", \"fc_layers.1.running_var\", \"fc_layers.1.num_batches_tracked\", \"fc_layers.3.weight\", \"fc_layers.3.bias\", \"fc_layers.4.running_mean\", \"fc_layers.4.running_var\", \"fc_layers.4.num_batches_tracked\". \n\tsize mismatch for gated_layers.0.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l0: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l0: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for fc_layers.0.weight: copying a param with shape torch.Size([32, 320]) from checkpoint, the shape in current model is torch.Size([384, 960]).\n\tsize mismatch for fc_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for fc_layers.4.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1, 192]).\n\tsize mismatch for fc_layers.4.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "\n",
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=dict_ret[\"embedding_size\"],\n",
    "    gated_num_layers=dict_ret[\"gated_num_layers\"],\n",
    "    gated_hidden_size=dict_ret[\"gated_hidden_size\"],\n",
    "    gated_activation=dict_ret[\"gated_activation\"],\n",
    "    gated_dropout=float(dict_ret[\"gated_dropout\"]),\n",
    "    gated_graph_norm=int(dict_ret[\"gated_graph_norm\"]),\n",
    "    gated_batch_norm=int(dict_ret[\"gated_batch_norm\"]),\n",
    "    gated_residual=dict_ret[\"gated_residual\"],\n",
    "    gated_num_fc_layers=dict_ret[\"gated_num_fc_layers\"],\n",
    "    fc_num_layers=dict_ret[\"fc_layers\"],\n",
    "    fc_hidden_size=dict_ret[\"fc_hidden_size\"],\n",
    "    fc_activation=dict_ret[\"fc_activation\"],\n",
    "    fc_dropout=float(dict_ret[\"fc_dropout\"]),\n",
    "    fc_batch_norm=int(dict_ret[\"fc_batch_norm\"]),\n",
    "    num_lstm_iters=dict_ret[\"num_lstm_iters\"],\n",
    "    num_lstm_layers=dict_ret[\"num_lstm_layers\"],\n",
    "    conv=\"GatedGCNConv\",\n",
    ")\n",
    "\n",
    "print(\"-\" * 20 + \"now disabling gradients\" + \"-\" * 20)\n",
    "model.gated_layers.requires_grad_(False)\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"checkpoint.pkl\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24432/2660373937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=dict_ret[\"embedding_size\"],\n",
    "    gated_num_layers=dict_ret[\"gated_num_layers\"],\n",
    "    gated_hidden_size=dict_ret[\"gated_hidden_size\"],\n",
    "    gated_activation=dict_ret[\"gated_activation\"],\n",
    "    gated_dropout=float(dict_ret[\"gated_dropout\"]),\n",
    "    gated_graph_norm=int(dict_ret[\"gated_graph_norm\"]),\n",
    "    gated_batch_norm=int(dict_ret[\"gated_batch_norm\"]),\n",
    "    gated_residual=dict_ret[\"gated_residual\"],\n",
    "    gated_num_fc_layers=dict_ret[\"gated_num_fc_layers\"],\n",
    "    fc_num_layers=dict_ret[\"fc_layers\"],\n",
    "    fc_hidden_size=dict_ret[\"fc_hidden_size\"],\n",
    "    fc_activation=dict_ret[\"fc_activation\"],\n",
    "    fc_dropout=float(dict_ret[\"fc_dropout\"]),\n",
    "    fc_batch_norm=int(dict_ret[\"fc_batch_norm\"]),\n",
    "    num_lstm_iters=dict_ret[\"num_lstm_iters\"],\n",
    "    num_lstm_layers=dict_ret[\"num_lstm_layers\"],\n",
    "    conv=\"GatedGCNConv\",\n",
    ")\n",
    "\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "model_ref = home+\"/Documents/Dataset/mg/\"\n",
    "\n",
    "#checkpoint = torch.load(model_ref + \"checkpoint.pkl\")\n",
    "#model.load_state_dict(checkpoint[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import networkx as nx \n",
    "\n",
    "path_mg_data = \"/home/santiagovargas/Documents/Dataset/mg_dataset/\"\n",
    "path_json = path_mg_data + \"20220613_reaction_data.json\"\n",
    "mg_df = pd.read_json(path_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "number of rxn failed: 141\n",
      "number of reactions with two products: 1326\n",
      "number of reactions with three products: 141\n"
     ]
    }
   ],
   "source": [
    "from bondnet.core.molwrapper import create_wrapper_mol_from_atoms_and_bonds\n",
    "from bondnet.core.reaction import Reaction\n",
    "\n",
    "error = 0 \n",
    "two_product_count = 0\n",
    "three_prouct_count = 0\n",
    "\n",
    "for index, row in mg_df.iterrows():\n",
    "\n",
    "    # handle reactant \n",
    "    species = [i['name'] for i in row['reactant_molecule_graph'][\"molecule\"][\"sites\"]]\n",
    "    coords = [i[\"xyz\"] for i in row['reactant_molecule_graph'][\"molecule\"][\"sites\"]]\n",
    "    bonds = row['reactant_bonds']\n",
    "    charge = row['charge']\n",
    "    \n",
    "    reactant = create_wrapper_mol_from_atoms_and_bonds(\n",
    "        species, coords, bonds, charge=charge\n",
    "        )\n",
    "    reactant_list = [reactant]\n",
    "\n",
    "    # handle products\n",
    "    # check subgraphs first\n",
    "    product_list = []\n",
    "    num_nodes = 0\n",
    "    for i in row[\"composition\"].items():\n",
    "        num_nodes += int(i[-1])\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from([int(i) for i in range(num_nodes)])\n",
    "    for i in row[\"product_bonds\"]: G.add_edge(i[0], i[1])\n",
    "    sub_graphs = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "\n",
    "    # still no handling for rxns A --> B + C +....\n",
    "    if(len(sub_graphs) > 2): three_prouct_count += 1\n",
    "    # handle A --> B + C\n",
    "    elif(len(sub_graphs) == 2):\n",
    "        product_list = []\n",
    "        for sg in sub_graphs:  \n",
    "            two_product_count += 1\n",
    "            nodes = list(sg.nodes())\n",
    "            bonds = list(sg.edges())\n",
    "            bond_reindex_list = []\n",
    "            species = [row['product_molecule_graph'][\"molecule\"][\"sites\"][sub_ind]['name'] for sub_ind in list(sg.nodes())]\n",
    "            coords = [row['product_molecule_graph'][\"molecule\"][\"sites\"][sub_ind][\"xyz\"] for sub_ind in list(sg.nodes())]\n",
    "            charge = row['charge']\n",
    "            for origin_bond_ind in row[\"product_bonds\"]:\n",
    "                check = any(item in origin_bond_ind for item in nodes)\n",
    "                if(check): \n",
    "                    bond_orig = nodes.index(origin_bond_ind[0])\n",
    "                    bond_targ = nodes.index(origin_bond_ind[1])\n",
    "                    bond_reindex_list.append([bond_orig, bond_targ])\n",
    "            \n",
    "                product = create_wrapper_mol_from_atoms_and_bonds(\n",
    "                species, coords, bond_reindex_list, charge=charge\n",
    "                )\n",
    "            product_list.append(product)\n",
    "\n",
    "    #handle A --> B \n",
    "    else: \n",
    "        species = [i['name'] for i in row['product_molecule_graph'][\"molecule\"][\"sites\"]]\n",
    "        coords = [i[\"xyz\"] for i in row['product_molecule_graph'][\"molecule\"][\"sites\"]]\n",
    "        bonds = row['product_bonds']\n",
    "        charge = row['charge']\n",
    "        free_energy = row['product_free_energy']\n",
    "        product = create_wrapper_mol_from_atoms_and_bonds(\n",
    "            species = species, \n",
    "            coords = coords, \n",
    "            bonds = bonds, \n",
    "            charge=charge\n",
    "            )\n",
    "        product_list = [product]\n",
    "    try: \n",
    "        rxn = Reaction(\n",
    "            reactants = reactant_list, \n",
    "            products=product_list, \n",
    "            broken_bond = row[\"bonds_broken\"],\n",
    "            free_energy= row[\"dE_barrier\"],\n",
    "            identifier = row[\"reaction_id\"]\n",
    "            )\n",
    "    except: \n",
    "        print(product_list)\n",
    "        error += 1\n",
    "print(\"number of rxn failed: \" + str(error))\n",
    "print(\"number of reactions with two products: \" + str(two_product_count))\n",
    "print(\"number of reactions with three products: \" + str(three_prouct_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for i, sg in enumerate(sub_graphs):pass\n",
    "#print(list(sg.nodes()))\n",
    "#mg_df.iloc[1]['product_molecule_graph'][\"molecule\"][\"sites\"][18]\n",
    "#mg_df.iloc[1]['product_molecule_graph'][\"molecule\"][\"sites\"][2]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.5000, 0.1000],\n",
      "        [2.2000, 1.3000, 1.7000]])\n",
      "torch.Size([2, 3])\n",
      "tensor([1, 2])\n",
      "torch.Size([2])\n",
      "tensor(0.8393)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "yhat = torch.Tensor([[0.5, 1.5, 0.1], [2.2, 1.3, 1.7]])\n",
    "print(yhat)\n",
    "print(yhat.shape)\n",
    "# tensor([[0.5000, 1.5000, 0.1000],\n",
    "#         [2.2000, 1.3000, 1.7000]])\n",
    "\n",
    "y = torch.Tensor([1, 2]).to(torch.long)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "# tensor([1, 2])\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "cel = loss(input=yhat, target=y)\n",
    "print(cel)\n",
    "# tensor(0.8393)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aug 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time, wandb, torch\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchmetrics import R2Score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from bondnet.model.metric import EarlyStopping\n",
    "from bondnet.data.dataset import ReactionNetworkDatasetGraphs\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.featurizer import (\n",
    "    AtomFeaturizerGraph,\n",
    "    BondAsNodeGraphFeaturizer,\n",
    "    GlobalFeaturizerGraph,\n",
    ")\n",
    "from bondnet.data.grapher import (\n",
    "    HeteroCompleteGraphFromDGLAndPandas,\n",
    ")\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "#from bondnet.scripts.create_label_file import read_input_files\n",
    "#from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.utils import seed_torch, pickle_dump, parse_settings\n",
    "from bondnet.model.training_utils import (\n",
    "    evaluate, \n",
    "    evaluate_classifier, \n",
    "    train, \n",
    "    train_classifier, \n",
    "    load_model\n",
    ")\n",
    "seed_torch()\n",
    "\n",
    "\n",
    "def evaluate_r2(model, nodes, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batched_graph, label in data_loader:\n",
    "            feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "            target = label[\"value\"]\n",
    "            \n",
    "            pred = model(batched_graph, feats, label[\"reaction\"])\n",
    "            pred = pred.view(-1)\n",
    "            target = target.view(-1)\n",
    "\n",
    "    r2_call = R2Score()\n",
    "    r2 = r2_call(pred, target)\n",
    "    return r2\n",
    "\n",
    "\n",
    "def get_grapher():\n",
    "\n",
    "    atom_featurizer = AtomFeaturizerGraph()\n",
    "    bond_featurizer = BondAsNodeGraphFeaturizer()\n",
    "    global_featurizer = GlobalFeaturizerGraph(allowed_charges=[-2, -1, 0, 1])\n",
    "    grapher = HeteroCompleteGraphFromDGLAndPandas(\n",
    "        atom_featurizer, bond_featurizer, global_featurizer\n",
    "    )\n",
    "    return grapher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the following settings:\n",
      "----------------------------------------\n",
      "Small Dataset?: True\n",
      "restore: True\n",
      "distributed: False\n",
      "on gpu: True\n",
      "num gpu: 1\n",
      "hyperparam save file: ./hyper.pkl\n",
      "dataset state dict: home/santiagovargas/Documents/Dataset/mg/dataset_state_dict.pkl\n",
      "model dir /home/santiagovargas/Documents/Dataset/mg/\n",
      "classifier False\n",
      "batch size: 128\n",
      "epochs: 500\n",
      "lr: 0.000100\n",
      "weight decay: 0.000\n",
      "early_stop: True\n",
      "scheduler: False\n",
      "transfer_epochs: 250\n",
      "transfer: True\n",
      "loss: False\n",
      "categories: 5\n",
      "embedding size: 24\n",
      "fc layers: 2\n",
      "fc hidden layer: [128, 64]\n",
      "gated layers: 3\n",
      "gated hidden layers: [64, 64, 64]\n",
      "num lstm iters: 6\n",
      "num lstm layer: 3\n",
      "gated fc layers: 2\n",
      "fc activation: ReLU\n",
      "fc batch norm: 0\n",
      "fc dropout: 0.00\n",
      "gated activation: ReLU\n",
      "gated dropout: 0.10\n",
      "gated batch norm: True\n",
      "gated graph norm: 0\n",
      "gated resid: True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best = 1e10\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "path_mg_data = \"../dataset/mg_dataset/\"\n",
    "dict_train = parse_settings(file=\"./training_runs/1/settings.txt\")\n",
    "path_mg_data = \"../../../dataset/mg_dataset/20220613_reaction_data.json\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on device: cuda\n"
     ]
    }
   ],
   "source": [
    "if(dict_train[\"classifier\"]):\n",
    "    classif_categories = 5 # update this later\n",
    "else:\n",
    "    classif_categories = None\n",
    "\n",
    "if dict_train[\"on_gpu\"]:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dict_train[\"gpu\"] = device\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    dict_train[\"gpu\"] = \"cpu\"\n",
    "\n",
    "print(\"train on device: {}\".format(dict_train[\"gpu\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file from: ../dataset/mg_dataset/20220613_reaction_data.json\n",
      "rxn raw len: 250\n",
      "Program finished in 1.1201213479998842 seconds\n",
      ".............failures.............\n",
      "reactions len: 26\n",
      "valid ind len: 26\n",
      "bond break fail count: \t\t0\n",
      "default fail count: \t\t224\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 26\n",
      "features: 66\n",
      "labels: 26\n",
      "molecules: 66\n",
      "constructing graphs & features....\n",
      "number of graphs valid: 66\n",
      "number of graphs: 66\n",
      "reading file from: ../dataset/mg_dataset/20220613_reaction_data.json\n",
      "rxn raw len: 250\n",
      "Program finished in 1.393154549999963 seconds\n",
      ".............failures.............\n",
      "reactions len: 26\n",
      "valid ind len: 26\n",
      "bond break fail count: \t\t0\n",
      "default fail count: \t\t224\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 26\n",
      "features: 66\n",
      "labels: 26\n",
      "molecules: 66\n",
      "constructing graphs & features....\n",
      "number of graphs valid: 66\n",
      "number of graphs: 66\n"
     ]
    }
   ],
   "source": [
    "path_mg_data = \"../dataset/mg_dataset/20220613_reaction_data.json\"\n",
    "\n",
    "dataset = ReactionNetworkDatasetGraphs(\n",
    "    grapher=get_grapher(), \n",
    "    file=path_mg_data, \n",
    "    out_file=\"./\", \n",
    "    target = 'ts', \n",
    "    classifier = dict_train[\"classifier\"], \n",
    "    classif_categories=classif_categories, \n",
    "    debug = dict_train[\"debug\"],\n",
    "    device = device\n",
    ")\n",
    "\n",
    "dataset_transfer = ReactionNetworkDatasetGraphs(\n",
    "    grapher=get_grapher(), file=path_mg_data, out_file=\"./\", \n",
    "    target = 'diff', \n",
    "    classifier = dict_train[\"classifier\"], \n",
    "    classif_categories=classif_categories, \n",
    "    debug = dict_train[\"debug\"],\n",
    "    device = device \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "for it, (bg, label) in enumerate(train_loader):\n",
    "    print(bg.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch, wandb\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork\n",
    "from bondnet.model.gated_reaction_network_classifier import GatedGCNReactionNetworkClassifier\n",
    "\n",
    "\n",
    "def train(model, nodes, data_loader, optimizer, device=None):\n",
    "    \"\"\"\n",
    "    basic loop for training a classifier. Gets loss and accuracy\n",
    "        \n",
    "    Args:\n",
    "        model(pytorch model): pytorch model\n",
    "        nodes(dict): node feature dictionary\n",
    "        data_loader(loader obj): loader object with data to eval\n",
    "        device(str): cpu/gpu\n",
    "    Returns: \n",
    "        accuracy (float): accuracy\n",
    "        loss (float): MSE\n",
    "    \"\"\"\n",
    "\n",
    "    loss_fn = WeightedMSELoss(reduction=\"sum\")\n",
    "    metric_fn = WeightedL1Loss(reduction=\"mean\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    count = 0.0\n",
    "\n",
    "    for it, (batched_graph, label) in enumerate(data_loader):\n",
    "        feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "        target = label[\"value\"]\n",
    "        norm_atom = label[\"norm_atom\"]\n",
    "        norm_bond = label[\"norm_bond\"]\n",
    "        stdev = label[\"scaler_stdev\"]\n",
    "\n",
    "        if device is not None:\n",
    "            feats = {k: v.to(device) for k, v in feats.items()}\n",
    "            target = target.to(device)\n",
    "            norm_atom = norm_atom.to(device)\n",
    "            norm_bond = norm_bond.to(device)\n",
    "            stdev = stdev.to(device)\n",
    "\n",
    "        try:\n",
    "            pred = model(batched_graph, feats, label[\"reaction\"], norm_atom, norm_bond)\n",
    "        except:\n",
    "            pred = model(batched_graph, feats, label[\"reaction\"])\n",
    "\n",
    "\n",
    "        # pred = pred.view(-1)\n",
    "        target_new_shape = (len(target), 1)\n",
    "        target = target.view(target_new_shape)\n",
    "        pred_new_shape = (len(pred), 1)\n",
    "        pred = pred.view(pred_new_shape)\n",
    "\n",
    "\n",
    "        try:\n",
    "            loss = loss_fn(pred, target, stdev)\n",
    "        except:\n",
    "            loss = loss_fn(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()  # here is the actual optimizer step\n",
    "\n",
    "        epoch_loss += loss.detach().item()\n",
    "        accuracy += metric_fn(pred, target, stdev).detach().item()\n",
    "        count += len(target)\n",
    "\n",
    "    epoch_loss /= it + 1\n",
    "    accuracy /= count\n",
    "\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Training w/ transfer...\n",
      "Number of Trainable Model Params: 378129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 43/250 [00:13<01:07,  3.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51725/217493002.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mdataset_transfer_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             )\n\u001b[1;32m     66\u001b[0m             val_acc_transfer = evaluate(\n",
      "\u001b[0;32m/tmp/ipykernel_51725/4259977100.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, nodes, data_loader, optimizer, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feat\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/bondnet/bondnet/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mreactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubselect_reactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrxn_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mbatched_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0msizes_atom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"atom\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0msizes_bond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bond\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(graphs, ndata, edata, node_attrs, edge_attrs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0metypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mgidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisjoint_union\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0mretg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDGLHeteroGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36mdisjoint_union\u001b[0;34m(metagraph, graphs)\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0mBatched\u001b[0m \u001b[0mHeterograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \"\"\"\n\u001b[0;32m-> 1254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroDisjointUnion_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisjoint_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnn_all_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbne_all_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.make_ret\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./object.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.make_ret_object\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mDo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0mGraphIndex\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dict_train['in_feats'] = dataset.feature_size\n",
    "model, optimizer = load_model(dict_train)\n",
    "model.to(device)\n",
    "\n",
    "trainset, valset, testset = train_validation_test_split(\n",
    "    dataset, validation=0.15, test=0.15\n",
    ")\n",
    "\n",
    "train_loader = DataLoaderReactionNetwork(trainset, batch_size=dict_train['batch_size'], \n",
    "shuffle=True)\n",
    "val_loader = DataLoaderReactionNetwork(\n",
    "    valset, batch_size=len(valset), shuffle=False\n",
    ")\n",
    "test_loader = DataLoaderReactionNetwork(\n",
    "    testset, batch_size=len(testset), shuffle=False\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.4, patience=25, verbose=True)\n",
    "stopper = EarlyStopping(patience=150)\n",
    "stopper_transfer = EarlyStopping(patience=150)\n",
    "\n",
    "if(dict_train['transfer']):\n",
    "\n",
    "    trainset_transfer, valset_tranfer, _ = train_validation_test_split(\n",
    "    dataset_transfer, validation=0.15, test=0.01\n",
    "    )\n",
    "    dataset_transfer_loader = DataLoaderReactionNetwork(\n",
    "        trainset_transfer, batch_size=dict_train['batch_size'], \n",
    "    shuffle=True)\n",
    "    dataset_transfer_loader_val = DataLoaderReactionNetwork(\n",
    "        valset_tranfer, batch_size=dict_train['batch_size'], \n",
    "    shuffle=True)\n",
    "\n",
    "    print(\"Initiating Training w/ transfer...\")\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"Number of Trainable Model Params: {}\".format(params))\n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(dict_train['transfer_epochs'])):\n",
    "        if(dict_train[\"classifier\"]):\n",
    "            _, _ = train_classifier(\n",
    "                model, \n",
    "                feature_names, \n",
    "                dataset_transfer_loader,\n",
    "                optimizer, \n",
    "                device = dict_train[\"gpu\"], \n",
    "                categories = classif_categories\n",
    "            )\n",
    "            val_acc_transfer, f1_score = evaluate_classifier(\n",
    "                model, \n",
    "                feature_names, \n",
    "                dataset_transfer_loader_val, \n",
    "                device = dict_train[\"gpu\"],\n",
    "                categories = classif_categories\n",
    "            )\n",
    "        else:\n",
    "            _, _ = train(\n",
    "                model, \n",
    "                feature_names, \n",
    "                dataset_transfer_loader, \n",
    "                optimizer, \n",
    "                device = dict_train[\"gpu\"]\n",
    "            )\n",
    "            val_acc_transfer = evaluate(\n",
    "                model, \n",
    "                feature_names, \n",
    "                dataset_transfer_loader_val, \n",
    "                device = dict_train[\"gpu\"]\n",
    "            )\n",
    "\n",
    "        if stopper_transfer.step(val_acc_transfer):\n",
    "            break\n",
    "\n",
    "    # freeze model layers but fc\n",
    "    model.gated_layers.requires_grad_(False)\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"Freezing Gated Layers....\")\n",
    "    print(\"Number of Trainable Model Params: {}\".format(params))\n",
    "\n",
    "t1 = time.time()\n",
    "# optimizer, loss function and metric function\n",
    "# main training loop\n",
    "if(dict_train[\"classifier\"]):\n",
    "    print(\"# Epoch     Loss         TrainAcc        ValAcc        ValF1\")\n",
    "else: \n",
    "    print(\"# Epoch     Loss         TrainAcc        ValAcc        ValR2\")        \n",
    "\n",
    "for epoch in range(dict_train['epochs']):\n",
    "    # train on training set\n",
    "    if(dict_train[\"classifier\"]):\n",
    "        loss, train_acc = train_classifier(\n",
    "            model, \n",
    "            feature_names, \n",
    "            train_loader, \n",
    "            optimizer, \n",
    "            device = dict_train[\"gpu\"],\n",
    "            categories = classif_categories\n",
    "        )\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_acc, f1_score = evaluate_classifier(\n",
    "            model, \n",
    "            feature_names, \n",
    "            val_loader, \n",
    "            device = dict_train[\"gpu\"],\n",
    "            categories = classif_categories\n",
    "        )\n",
    "\n",
    "        wandb.log({\"acc validation\": val_acc})\n",
    "        wandb.log({\"f1 validation\": f1_score})\n",
    "        print(\n",
    "            \"{:5d}   {:12.6e}   {:12.2e}   {:12.6e}   {:.2f}\".format(\n",
    "                epoch, loss, train_acc, val_acc, f1_score\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    else: \n",
    "        loss, train_acc = train(\n",
    "        model, \n",
    "        feature_names, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        dict_train[\"gpu\"]\n",
    "        )\n",
    "        # evaluate on validation set\n",
    "        val_acc = evaluate(model, feature_names, val_loader, dict_train[\"gpu\"])\n",
    "        val_r2 = evaluate_r2(model, feature_names, val_loader)\n",
    "    \n",
    "\n",
    "        print(\n",
    "            \"{:5d}   {:12.6e}   {:12.2e}   {:12.6e}   {:.2f}\".format(\n",
    "                epoch, loss, train_acc, val_acc, val_r2\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # save checkpoint for best performing model\n",
    "    is_best = val_acc < best\n",
    "    if is_best:\n",
    "        best = val_acc\n",
    "        torch.save(model.state_dict(), \"checkpoint.pkl\")\n",
    "\n",
    "    if(dict_train[\"early_stop\"]):\n",
    "        if stopper.step(val_acc):\n",
    "            pickle_dump(\n",
    "                best, dict_train[\"save_hyper_params\"]\n",
    "            )  # save results for hyperparam tune\n",
    "            break\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "checkpoint = torch.load(\"checkpoint.pkl\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "if(dict_train[\"classifier\"]):\n",
    "    test_acc, test_f1 = evaluate_classifier(\n",
    "        model, \n",
    "        feature_names, \n",
    "        test_loader, \n",
    "        device = dict_train[\"gpu\"],\n",
    "        categories = classif_categories\n",
    "    )\n",
    "    print(\"Test Acc: {:12.6e}\".format(test_acc))\n",
    "    print(\"Test F1: {:12.6e}\".format(test_f1))\n",
    "\n",
    "\n",
    "else: \n",
    "    test_acc = evaluate(model, feature_names, test_loader)\n",
    "    print(\"TestAcc: {:12.6e}\".format(test_acc))\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time to Training: {:5.1f} seconds\".format(float(t2 - t1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c205a9eb4435b0aa27aaf0e9c4340d2b9512e0cc8b49dbd290219ad3711c312f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('bondnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
