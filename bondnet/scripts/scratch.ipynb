{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from rdkit import RDLogger\n",
    "\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from bondnet.data.dataset import ReactionNetworkDataset\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.featurizer import (\n",
    "    AtomFeaturizerMinimum,\n",
    "    AtomFeaturizerFull,\n",
    "    BondAsNodeFeaturizerMinimum,\n",
    "    GlobalFeaturizer,\n",
    "    BondAsNodeFeaturizerFull,\n",
    ")\n",
    "from bondnet.data.grapher import HeteroMoleculeGraph\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork\n",
    "from bondnet.scripts.create_label_file import read_input_files\n",
    "from bondnet.model.metric import WeightedL1Loss\n",
    "from bondnet.prediction.load_model import load_dataset, load_model\n",
    "from bondnet.utils import seed_torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def train(optimizer, model, nodes, data_loader, loss_fn, metric_fn):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    count = 0.0\n",
    "\n",
    "    for it, (batched_graph, label) in enumerate(data_loader):\n",
    "        feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "        target = label[\"value\"]\n",
    "        stdev = label[\"scaler_stdev\"]\n",
    "\n",
    "        pred = model(batched_graph, feats, label[\"reaction\"])\n",
    "        pred = pred.view(-1)\n",
    "\n",
    "        loss = loss_fn(pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()  # here is the actual optimizer step\n",
    "\n",
    "        epoch_loss += loss.detach().item()\n",
    "        accuracy += metric_fn(pred, target, stdev).detach().item()\n",
    "        count += len(target)\n",
    "\n",
    "    epoch_loss /= it + 1\n",
    "    accuracy /= count\n",
    "\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, nodes, data_loader, metric_fn):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        accuracy = 0.0\n",
    "        count = 0.0\n",
    "\n",
    "        for batched_graph, label in data_loader:\n",
    "            feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "            target = label[\"value\"]\n",
    "            stdev = label[\"scaler_stdev\"]\n",
    "\n",
    "            pred = model(batched_graph, feats, label[\"reaction\"])\n",
    "            pred = pred.view(-1)\n",
    "\n",
    "            accuracy += metric_fn(pred, target, stdev).detach().item()\n",
    "            count += len(target)\n",
    "\n",
    "    return accuracy / count\n",
    "\n",
    "\n",
    "def get_grapher():\n",
    "    atom_featurizer = AtomFeaturizerMinimum()\n",
    "    bond_featurizer = BondAsNodeFeaturizerMinimum()\n",
    "    # bond_featurizer = BondAsNodeFeaturizerFull()\n",
    "    # our example dataset contains molecules of charges -1, 0, and 1\n",
    "    global_featurizer = GlobalFeaturizer(allowed_charges=[-2, -1, 0, 1, 2])\n",
    "\n",
    "    grapher = HeteroMoleculeGraph(atom_featurizer, bond_featurizer, global_featurizer)\n",
    "\n",
    "    return grapher\n",
    "\n",
    "\n",
    "def parse_settings(file=\"./input_files/input_1.txt\"):\n",
    "    # some default values that get written over if in the file\n",
    "    test = True\n",
    "    epochs = 10\n",
    "    embedding_size = 24\n",
    "\n",
    "    fc_hidden_size = [128, 64]\n",
    "    fc_layers = -1\n",
    "    fc_activation = \"ReLU\"\n",
    "    fc_batch_norm = 0\n",
    "    fc_dropout = 0.0\n",
    "\n",
    "    gated_hidden_size = [64, 64, 64]\n",
    "    gated_layers = -1\n",
    "    gated_batch_norm = 0\n",
    "    gated_graph_norm = 0\n",
    "    gated_dropout = 0.0\n",
    "    gated_activation = \"ReLU\"\n",
    "\n",
    "    num_lstm_layers = 3\n",
    "    num_lstm_iters = 5\n",
    "\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for i in lines:\n",
    "            if len(i.split()) > 1:\n",
    "                if i.split()[0] == \"test\":\n",
    "                    test = bool(i.split()[1])\n",
    "                if i.split()[0] == \"epochs\":\n",
    "                    epochs = int(i.split()[1])\n",
    "                if i.split()[0] == \"embedding_size\":\n",
    "                    embedding_size = int(i.split()[1])\n",
    "\n",
    "                if i.split()[0] == \"gated_hidden_size\":\n",
    "                    gated_hidden_size = [int(j) for j in i.split()[1:]]\n",
    "                if i.split()[0] == \"gated_layers\":\n",
    "                    gated_layers = int(i.split()[1])\n",
    "                if i.split()[0] == \"gated_dropout\":\n",
    "                    gated_dropout = float(i.split()[1])\n",
    "                if i.split()[0] == \"gated_graph_norm\":\n",
    "                    gated_graph_norm = int(i.split()[1])\n",
    "                if i.split()[0] == \"gated_batch_norm\":\n",
    "                    gated_batch_norm = int(i.split()[1])\n",
    "                if i.split()[0] == \"gated_activation\":\n",
    "                    gated_activation = str(i.split()[1])\n",
    "\n",
    "                if i.split()[0] == \"fc_hidden_size\":\n",
    "                    fc_hidden_size = [int(j) for j in i.split()[1:]]\n",
    "                if i.split()[0] == \"fc_layers\":\n",
    "                    fc_layers = int(i.split()[1])\n",
    "                if i.split()[0] == \"fc_activation\":\n",
    "                    fc_activation = str(i.split()[1])\n",
    "                if i.split()[0] == \"fc_batch_norm\":\n",
    "                    fc_batch_norm = int(i.split()[1])\n",
    "                if i.split()[0] == \"fc_dropout\":\n",
    "                    fc_dropout = float(i.split()[1])\n",
    "\n",
    "                if i.split()[0] == \"num_lstm_iters\":\n",
    "                    num_lstm_iters = int(i.split()[1])\n",
    "                if i.split()[0] == \"num_lstm_layers\":\n",
    "                    num_lstm_layers = int(i.split()[1])\n",
    "\n",
    "        if gated_layers == -1:\n",
    "            gated_layers = len(gated_hidden_size)\n",
    "        if fc_layers == -1:\n",
    "            fc_layers = len(fc_hidden_size)\n",
    "\n",
    "        print(\"using the following settings:\")\n",
    "        print(\"--\" * 20)\n",
    "\n",
    "        print(\"epochs: {:1d}\".format(epochs))\n",
    "        print(\"Small Dataset?: \" + str(test))\n",
    "        print(\"embedding size: {:1d}\".format(embedding_size))\n",
    "\n",
    "        print(\"fc layers: {:1d}\".format(fc_layers))\n",
    "        print(\"fc hidden layer: \" + str(fc_hidden_size))\n",
    "        print(\"fc activation: \" + str(fc_activation))\n",
    "        print(\"fc batch norm: \" + str(fc_batch_norm))\n",
    "        print(\"fc dropout: {:.2f}\".format(fc_dropout))\n",
    "\n",
    "        print(\"gated layers: {:1d}\".format(gated_layers))\n",
    "        print(\"gated hidden layers: \" + str(gated_hidden_size))\n",
    "        print(\"gated activation: \" + str(gated_activation))\n",
    "        print(\"gated dropout: {:.2f}\".format(gated_dropout))\n",
    "        print(\"gated batch norm: \" + str(gated_batch_norm))\n",
    "        print(\"gated graph norm: \" + str(gated_graph_norm))\n",
    "\n",
    "        print(\"num lstm iters: \" + str(num_lstm_iters))\n",
    "        print(\"num lstm layer: \" + str(num_lstm_layers))\n",
    "        print(\"--\" * 20)\n",
    "\n",
    "        dict_ret = {}\n",
    "        dict_ret[\"test\"] = test\n",
    "        dict_ret[\"epochs\"] = epochs\n",
    "        dict_ret[\"embedding_size\"] = embedding_size\n",
    "\n",
    "        dict_ret[\"fc_hidden_size\"] = fc_hidden_size\n",
    "        dict_ret[\"fc_layers\"] = fc_layers\n",
    "        dict_ret[\"fc_dropout\"] = fc_dropout\n",
    "        dict_ret[\"fc_batch_norm\"] = fc_batch_norm\n",
    "        dict_ret[\"fc_activation\"] = fc_activation\n",
    "\n",
    "        dict_ret[\"gated_hidden_size\"] = gated_hidden_size\n",
    "        dict_ret[\"gated_layers\"] = gated_layers\n",
    "        dict_ret[\"gated_activation\"] = gated_activation\n",
    "        dict_ret[\"gated_graph_norm\"] = gated_graph_norm\n",
    "        dict_ret[\"gated_batch_norm\"] = gated_batch_norm\n",
    "        dict_ret[\"gated_dropout\"] = gated_dropout\n",
    "\n",
    "        dict_ret[\"num_lstm_iters\"] = num_lstm_iters\n",
    "        dict_ret[\"num_lstm_layers\"] = num_lstm_layers\n",
    "\n",
    "        return dict_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the following settings:\n",
      "----------------------------------------\n",
      "restore: True\n",
      "distributed: False\n",
      "batch size: 100\n",
      "on gpu: False\n",
      "epochs: 1000\n",
      "embedding size: 24\n",
      "fc layers: 2\n",
      "fc hidden layer: [384, 192]\n",
      "gated layers: 4\n",
      "gated hidden layers: [192, 192, 192, 192]\n",
      "gated fc layers: 2\n",
      "num lstm iters: 6\n",
      "num lstm layer: 3\n",
      "num gpu: 1\n",
      "hyperparam save file: ./hyper.pkl\n",
      "dataset state dict: home/santiagovargas/Documents/Dataset/mg/dataset_state_dict.pkl\n",
      "model dir/home/santiagovargas/Documents/Dataset/mg/\n",
      "Small Dataset?: False\n",
      "lr: 0.001000\n",
      "weight decay: 0.000\n",
      "fc activation: ReLU\n",
      "fc batch norm: 0\n",
      "fc dropout: 0.00\n",
      "gated activation: ReLU\n",
      "gated dropout: 0.10\n",
      "gated batch norm: True\n",
      "gated graph norm: 0\n",
      "gated resid: True\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): GatedGCNConv(\n",
       "    (activation): ReLU()\n",
       "    (A): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (B): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (C): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (D): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (E): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (F): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (G): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (H): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (I): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=24, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bn_node_h): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_e): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_u): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (1): GatedGCNConv(\n",
       "    (activation): ReLU()\n",
       "    (A): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (B): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (C): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (D): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (E): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (F): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (G): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (H): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (I): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bn_node_h): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_e): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_u): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (2): GatedGCNConv(\n",
       "    (activation): ReLU()\n",
       "    (A): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (B): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (C): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (D): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (E): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (F): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (G): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (H): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (I): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bn_node_h): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_e): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_u): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (3): GatedGCNConv(\n",
       "    (activation): ReLU()\n",
       "    (A): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (B): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (C): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (D): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (E): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (F): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (G): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (H): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (I): LinearN(\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bn_node_h): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_e): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_node_u): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bondnet.utils import parse_settings\n",
    "\n",
    "dict_ret = parse_settings(file=\"./input_files/input_2.txt\")\n",
    "model = load_model(dict_ret[\"model_path\"])\n",
    "model.gated_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheesh\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model trained with a dataset having species: C,F,H,Mg,N,O,S; Cannot make predictions for molecule containing species: Li. Note that two models trained on different datasets are provided: the `pubchem` supports C, H, O, N and the `bdncm` supports C, H, O, F, Li. You may want to switch the model if you see this message.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79646/74992533.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmolecules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     extra_features=attrs)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bondnet/bondnet/prediction/load_model.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(model_path, molecules, labels, extra_features)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mstate_dict_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset_state_dict.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0m_check_species\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolecules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0m_check_charge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bondnet/bondnet/prediction/load_model.py\u001b[0m in \u001b[0;36m_check_species\u001b[0;34m(molecules, state_dict_filename)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0msupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_species\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         raise ValueError(\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0;34mf\"Model trained with a dataset having species: {supported}; Cannot make \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;34mf\"predictions for molecule containing species: {not_supported}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;34mf\"Note that two models trained on different datasets are provided: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Model trained with a dataset having species: C,F,H,Mg,N,O,S; Cannot make predictions for molecule containing species: Li. Note that two models trained on different datasets are provided: the `pubchem` supports C, H, O, N and the `bdncm` supports C, H, O, F, Li. You may want to switch the model if you see this message."
     ]
    }
   ],
   "source": [
    "if bool(dict_ret[\"test\"]):\n",
    "    mols, attrs, labels = read_input_files(\n",
    "        \"examples/train/molecules.sdf\",\n",
    "        \"examples/train/molecule_attributes.yaml\",\n",
    "        \"examples/train/reactions.yaml\",\n",
    "    )\n",
    "else:\n",
    "    # todo\n",
    "    # mols, attrs, labels = read_input_files(\n",
    "    #    'examples/train/molecules_libe.sdf',\n",
    "    #    'examples/train/molecule_attributes_libe.yaml',\n",
    "    #    'examples/train/reactions_libe.yaml',\n",
    "    # )\n",
    "\n",
    "    # todo\n",
    "    # mols_mg, attrs_mg, labels_mg = read_input_files(\n",
    "    #    '../train/molecules_libe.sdf',\n",
    "    #    '../train/train/molecule_attributes_libe.yaml',\n",
    "    #    '../train/train/reactions_libe.yaml',\n",
    "    # )\n",
    "\n",
    "    mols, attrs, labels = read_input_files(\n",
    "        \"examples/train/molecules.sdf\",\n",
    "        \"examples/train/molecule_attributes.yaml\",\n",
    "        \"examples/train/reactions.yaml\",\n",
    "    )\n",
    "\n",
    "    print(\"sheesh\")\n",
    "    # mols, attrs , labels = read_input_files()\n",
    "\n",
    "\n",
    "# dataset = ReactionNetworkDataset(\n",
    "#    grapher=get_grapher(),\n",
    "#    molecules=mols,\n",
    "#    labels=labels,\n",
    "#    extra_features=attrs\n",
    "# )\n",
    "# def load_dataset(model_path, molecules, labels, extra_features):\n",
    "model = load_model(dict_ret[\"model_path\"])\n",
    "dataset = load_dataset(\n",
    "    dict_ret[\"model_path\"], molecules=mols, labels=labels, extra_features=attrs\n",
    ")\n",
    "\n",
    "\n",
    "trainset, valset, testset = train_validation_test_split(\n",
    "    dataset, validation=0.1, test=0.1\n",
    ")\n",
    "\n",
    "# we train with a batch size of 100\n",
    "train_loader = DataLoaderReactionNetwork(trainset, batch_size=100, shuffle=True)\n",
    "val_loader = DataLoaderReactionNetwork(valset, batch_size=len(valset), shuffle=False)\n",
    "test_loader = DataLoaderReactionNetwork(testset, batch_size=len(testset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_features: 15, 7, 9\n",
      "{'atom': 13, 'bond': 7, 'global': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"required_features: 15, 7, 9\")\n",
    "print(dataset.feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch     Loss         TrainAcc        ValAcc\n",
      "    0   8.354622e-01   2.457747e+00   2.090321e+00\n",
      "    5   5.997426e-01   2.131326e+00   1.854207e+00\n",
      "   10   3.939752e-01   1.736316e+00   1.741784e+00\n",
      "   15   4.004955e-01   1.777406e+00   1.947630e+00\n",
      "   20   3.577470e-01   1.632960e+00   1.456190e+00\n",
      "   25   2.316015e-01   1.361877e+00   1.209444e+00\n",
      "   30   2.086340e-01   1.235057e+00   1.274223e+00\n",
      "   35   2.070761e-01   1.257603e+00   1.237815e+00\n",
      "   40   1.872679e-01   1.174746e+00   1.171825e+00\n",
      "   45   1.694346e-01   1.121845e+00   1.209740e+00\n",
      "   50   1.505942e-01   1.087599e+00   1.227573e+00\n",
      "   55   1.248520e-01   1.002119e+00   1.212870e+00\n",
      "   60   1.600399e-01   1.060676e+00   1.172067e+00\n",
      "   65   1.364062e-01   1.022181e+00   1.232711e+00\n",
      "   70   1.377577e-01   1.037374e+00   1.191099e+00\n",
      "   75   1.240184e-01   9.555707e-01   1.293485e+00\n",
      "   80   1.012025e-01   8.473748e-01   1.273484e+00\n",
      "   85   9.228709e-02   8.663695e-01   1.098703e+00\n",
      "   90   7.441843e-02   7.834238e-01   1.040848e+00\n",
      "   95   7.522986e-02   7.631644e-01   1.032907e+00\n",
      "  100   6.878521e-02   7.609694e-01   1.077767e+00\n",
      "  105   7.537310e-02   7.894107e-01   1.034274e+00\n",
      "  110   7.667498e-02   7.767191e-01   1.067675e+00\n",
      "  115   7.484786e-02   7.363903e-01   1.091353e+00\n",
      "  120   6.422543e-02   7.039043e-01   1.234220e+00\n",
      "  125   8.075837e-02   7.682405e-01   1.058505e+00\n",
      "  130   6.263306e-02   6.846303e-01   1.048112e+00\n",
      "  135   7.054856e-02   6.666646e-01   9.010829e-01\n",
      "  140   5.400955e-02   6.341265e-01   9.818805e-01\n",
      "  145   6.545419e-02   6.792798e-01   1.031975e+00\n",
      "  150   6.300042e-02   6.633443e-01   1.114793e+00\n",
      "  155   5.747807e-02   6.613629e-01   1.197821e+00\n",
      "  160   6.766270e-02   7.292619e-01   1.109440e+00\n",
      "  165   7.155528e-02   6.466055e-01   1.062312e+00\n",
      "  170   5.606647e-02   6.650330e-01   9.975495e-01\n",
      "  175   5.539288e-02   6.385573e-01   9.832197e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54216/3889286270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# train on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=dict_ret[\"embedding_size\"],\n",
    "    gated_num_layers=dict_ret[\"gated_num_layers\"],\n",
    "    gated_hidden_size=dict_ret[\"gated_hidden_size\"],\n",
    "    gated_activation=dict_ret[\"gated_activation\"],\n",
    "    gated_dropout=float(dict_ret[\"gated_dropout\"]),\n",
    "    gated_graph_norm=int(dict_ret[\"gated_graph_norm\"]),\n",
    "    gated_batch_norm=int(dict_ret[\"gated_batch_norm\"]),\n",
    "    fc_num_layers=dict_ret[\"fc_layers\"],\n",
    "    fc_hidden_size=dict_ret[\"fc_hidden_size\"],\n",
    "    fc_activation=dict_ret[\"fc_activation\"],\n",
    "    fc_dropout=float(dict_ret[\"fc_dropout\"]),\n",
    "    fc_batch_norm=int(dict_ret[\"fc_batch_norm\"]),\n",
    "    num_lstm_iters=dict_ret[\"num_lstm_iters\"],\n",
    "    num_lstm_layers=dict_ret[\"num_lstm_layers\"],\n",
    "    conv=\"GatedGCNConv\",\n",
    ")\n",
    "\n",
    "# optimizer, loss function and metric function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = MSELoss(reduction=\"mean\")\n",
    "metric = WeightedL1Loss(reduction=\"sum\")\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "best = 1e10\n",
    "\n",
    "# main training loop\n",
    "print(\"# Epoch     Loss         TrainAcc        ValAcc\")\n",
    "t1 = time.time()\n",
    "\n",
    "for epoch in range(dict_ret[\"epochs\"]):\n",
    "    if epoch % 5 == 0:\n",
    "        # train on training set\n",
    "        loss, train_acc = train(\n",
    "            optimizer, model, feature_names, train_loader, loss_func, metric\n",
    "        )\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_acc = evaluate(model, feature_names, val_loader, metric)\n",
    "\n",
    "        # save checkpoint for best performing model\n",
    "        if val_acc < best:\n",
    "            best = val_acc\n",
    "            torch.save(model.state_dict(), \"checkpoint.pkl\")\n",
    "\n",
    "        print(\n",
    "            \"{:5d}   {:12.6e}   {:12.6e}   {:12.6e}\".format(\n",
    "                epoch, loss, train_acc, val_acc\n",
    "            )\n",
    "        )\n",
    "t2 = time.time()\n",
    "\n",
    "\n",
    "# load best performing model and test it's performance on the test set\n",
    "checkpoint = torch.load(\"checkpoint.pkl\")\n",
    "model.load_state_dict(checkpoint)\n",
    "test_acc = evaluate(model, feature_names, test_loader, metric)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "print(\"TestAcc: {:12.6e}\".format(test_acc))\n",
    "print(\"Time to Train: {:5.1f} seconds\".format(float(t2 - t1)))\n",
    "print(\"Number of Trainable Model Params: {}\".format(params))\n",
    "\n",
    "\n",
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=dict_ret[\"embedding_size\"],\n",
    "    gated_num_layers=dict_ret[\"gated_num_layers\"],\n",
    "    gated_hidden_size=dict_ret[\"gated_hidden_size\"],\n",
    "    gated_activation=dict_ret[\"gated_activation\"],\n",
    "    gated_dropout=float(dict_ret[\"gated_dropout\"]),\n",
    "    gated_graph_norm=int(dict_ret[\"gated_graph_norm\"]),\n",
    "    gated_batch_norm=int(dict_ret[\"gated_batch_norm\"]),\n",
    "    gated_residual=dict_ret[\"gated_residual\"],\n",
    "    gated_num_fc_layers=dict_ret[\"gated_num_fc_layers\"],\n",
    "    fc_num_layers=dict_ret[\"fc_layers\"],\n",
    "    fc_hidden_size=dict_ret[\"fc_hidden_size\"],\n",
    "    fc_activation=dict_ret[\"fc_activation\"],\n",
    "    fc_dropout=float(dict_ret[\"fc_dropout\"]),\n",
    "    fc_batch_norm=int(dict_ret[\"fc_batch_norm\"]),\n",
    "    num_lstm_iters=dict_ret[\"num_lstm_iters\"],\n",
    "    num_lstm_layers=dict_ret[\"num_lstm_layers\"],\n",
    "    conv=\"GatedGCNConv\",\n",
    ")\n",
    "\n",
    "print(\"-\" * 20 + \"now disabling gradients\" + \"-\" * 20)\n",
    "model.gated_layers.requires_grad_(False)\n",
    "\n",
    "# model.fc_layers.requires_grad_(False)\n",
    "# model.readout_layer.requires_grad_(False)\n",
    "\n",
    "\n",
    "best = 1e10\n",
    "\n",
    "# main training loop\n",
    "print(\"# Epoch     Loss         TrainAcc        ValAcc\")\n",
    "t1 = time.time()\n",
    "\n",
    "for epoch in range(dict_ret[\"epochs\"]):\n",
    "    if epoch % 5 == 0:\n",
    "        # train on training set\n",
    "        loss, train_acc = train(\n",
    "            optimizer, model, feature_names, train_loader, loss_func, metric\n",
    "        )\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_acc = evaluate(model, feature_names, val_loader, metric)\n",
    "\n",
    "        # save checkpoint for best performing model\n",
    "\n",
    "        if val_acc < best:\n",
    "            best = val_acc\n",
    "            torch.save(model.state_dict(), \"checkpoint.pkl\")\n",
    "\n",
    "        print(\n",
    "            \"{:5d}   {:12.6e}   {:12.6e}   {:12.6e}\".format(\n",
    "                epoch, loss, train_acc, val_acc\n",
    "            )\n",
    "        )\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "\n",
    "# load best performing model and test it's performance on the test set\n",
    "from os.path import expanduser\n",
    "\n",
    "# home = expanduser(\"~\")\n",
    "# model_directory = home+\"/Documents/Dataset/mg/checkpoint.pkl\"\n",
    "\n",
    "# checkpoint = torch.load(model_directory)\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# test_acc = evaluate(model, feature_names, test_loader, metric)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "print(\"TestAcc: {:12.6e}\".format(test_acc))\n",
    "print(\"Time to Train: {:5.1f} seconds\".format(float(t2 - t1)))\n",
    "print(\"Number of Trainable Model Params: {}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------now disabling gradients--------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GatedGCNReactionNetwork:\n\tMissing key(s) in state_dict: \"gated_layers.3.A.fc_layers.0.weight\", \"gated_layers.3.A.fc_layers.0.bias\", \"gated_layers.3.A.fc_layers.2.weight\", \"gated_layers.3.A.fc_layers.2.bias\", \"gated_layers.3.B.fc_layers.0.weight\", \"gated_layers.3.B.fc_layers.0.bias\", \"gated_layers.3.B.fc_layers.2.weight\", \"gated_layers.3.B.fc_layers.2.bias\", \"gated_layers.3.C.fc_layers.0.weight\", \"gated_layers.3.C.fc_layers.0.bias\", \"gated_layers.3.C.fc_layers.2.weight\", \"gated_layers.3.C.fc_layers.2.bias\", \"gated_layers.3.D.fc_layers.0.weight\", \"gated_layers.3.D.fc_layers.0.bias\", \"gated_layers.3.D.fc_layers.2.weight\", \"gated_layers.3.D.fc_layers.2.bias\", \"gated_layers.3.E.fc_layers.0.weight\", \"gated_layers.3.E.fc_layers.0.bias\", \"gated_layers.3.E.fc_layers.2.weight\", \"gated_layers.3.E.fc_layers.2.bias\", \"gated_layers.3.F.fc_layers.0.weight\", \"gated_layers.3.F.fc_layers.0.bias\", \"gated_layers.3.F.fc_layers.2.weight\", \"gated_layers.3.F.fc_layers.2.bias\", \"gated_layers.3.G.fc_layers.0.weight\", \"gated_layers.3.G.fc_layers.0.bias\", \"gated_layers.3.G.fc_layers.2.weight\", \"gated_layers.3.G.fc_layers.2.bias\", \"gated_layers.3.H.fc_layers.0.weight\", \"gated_layers.3.H.fc_layers.0.bias\", \"gated_layers.3.H.fc_layers.2.weight\", \"gated_layers.3.H.fc_layers.2.bias\", \"gated_layers.3.I.fc_layers.0.weight\", \"gated_layers.3.I.fc_layers.0.bias\", \"gated_layers.3.I.fc_layers.2.weight\", \"gated_layers.3.I.fc_layers.2.bias\", \"gated_layers.3.bn_node_h.weight\", \"gated_layers.3.bn_node_h.bias\", \"gated_layers.3.bn_node_h.running_mean\", \"gated_layers.3.bn_node_h.running_var\", \"gated_layers.3.bn_node_e.weight\", \"gated_layers.3.bn_node_e.bias\", \"gated_layers.3.bn_node_e.running_mean\", \"gated_layers.3.bn_node_e.running_var\", \"gated_layers.3.bn_node_u.weight\", \"gated_layers.3.bn_node_u.bias\", \"gated_layers.3.bn_node_u.running_mean\", \"gated_layers.3.bn_node_u.running_var\", \"fc_layers.2.weight\", \"fc_layers.2.bias\". \n\tUnexpected key(s) in state_dict: \"readout_layer.layers.atom.lstm.weight_ih_l3\", \"readout_layer.layers.atom.lstm.weight_hh_l3\", \"readout_layer.layers.atom.lstm.bias_ih_l3\", \"readout_layer.layers.atom.lstm.bias_hh_l3\", \"readout_layer.layers.atom.lstm.weight_ih_l4\", \"readout_layer.layers.atom.lstm.weight_hh_l4\", \"readout_layer.layers.atom.lstm.bias_ih_l4\", \"readout_layer.layers.atom.lstm.bias_hh_l4\", \"readout_layer.layers.bond.lstm.weight_ih_l3\", \"readout_layer.layers.bond.lstm.weight_hh_l3\", \"readout_layer.layers.bond.lstm.bias_ih_l3\", \"readout_layer.layers.bond.lstm.bias_hh_l3\", \"readout_layer.layers.bond.lstm.weight_ih_l4\", \"readout_layer.layers.bond.lstm.weight_hh_l4\", \"readout_layer.layers.bond.lstm.bias_ih_l4\", \"readout_layer.layers.bond.lstm.bias_hh_l4\", \"fc_layers.6.weight\", \"fc_layers.6.bias\", \"fc_layers.1.weight\", \"fc_layers.1.bias\", \"fc_layers.1.running_mean\", \"fc_layers.1.running_var\", \"fc_layers.1.num_batches_tracked\", \"fc_layers.3.weight\", \"fc_layers.3.bias\", \"fc_layers.4.running_mean\", \"fc_layers.4.running_var\", \"fc_layers.4.num_batches_tracked\". \n\tsize mismatch for gated_layers.0.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l0: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l0: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for fc_layers.0.weight: copying a param with shape torch.Size([32, 320]) from checkpoint, the shape in current model is torch.Size([384, 960]).\n\tsize mismatch for fc_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for fc_layers.4.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1, 192]).\n\tsize mismatch for fc_layers.4.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24432/339809252.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoint.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1045\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GatedGCNReactionNetwork:\n\tMissing key(s) in state_dict: \"gated_layers.3.A.fc_layers.0.weight\", \"gated_layers.3.A.fc_layers.0.bias\", \"gated_layers.3.A.fc_layers.2.weight\", \"gated_layers.3.A.fc_layers.2.bias\", \"gated_layers.3.B.fc_layers.0.weight\", \"gated_layers.3.B.fc_layers.0.bias\", \"gated_layers.3.B.fc_layers.2.weight\", \"gated_layers.3.B.fc_layers.2.bias\", \"gated_layers.3.C.fc_layers.0.weight\", \"gated_layers.3.C.fc_layers.0.bias\", \"gated_layers.3.C.fc_layers.2.weight\", \"gated_layers.3.C.fc_layers.2.bias\", \"gated_layers.3.D.fc_layers.0.weight\", \"gated_layers.3.D.fc_layers.0.bias\", \"gated_layers.3.D.fc_layers.2.weight\", \"gated_layers.3.D.fc_layers.2.bias\", \"gated_layers.3.E.fc_layers.0.weight\", \"gated_layers.3.E.fc_layers.0.bias\", \"gated_layers.3.E.fc_layers.2.weight\", \"gated_layers.3.E.fc_layers.2.bias\", \"gated_layers.3.F.fc_layers.0.weight\", \"gated_layers.3.F.fc_layers.0.bias\", \"gated_layers.3.F.fc_layers.2.weight\", \"gated_layers.3.F.fc_layers.2.bias\", \"gated_layers.3.G.fc_layers.0.weight\", \"gated_layers.3.G.fc_layers.0.bias\", \"gated_layers.3.G.fc_layers.2.weight\", \"gated_layers.3.G.fc_layers.2.bias\", \"gated_layers.3.H.fc_layers.0.weight\", \"gated_layers.3.H.fc_layers.0.bias\", \"gated_layers.3.H.fc_layers.2.weight\", \"gated_layers.3.H.fc_layers.2.bias\", \"gated_layers.3.I.fc_layers.0.weight\", \"gated_layers.3.I.fc_layers.0.bias\", \"gated_layers.3.I.fc_layers.2.weight\", \"gated_layers.3.I.fc_layers.2.bias\", \"gated_layers.3.bn_node_h.weight\", \"gated_layers.3.bn_node_h.bias\", \"gated_layers.3.bn_node_h.running_mean\", \"gated_layers.3.bn_node_h.running_var\", \"gated_layers.3.bn_node_e.weight\", \"gated_layers.3.bn_node_e.bias\", \"gated_layers.3.bn_node_e.running_mean\", \"gated_layers.3.bn_node_e.running_var\", \"gated_layers.3.bn_node_u.weight\", \"gated_layers.3.bn_node_u.bias\", \"gated_layers.3.bn_node_u.running_mean\", \"gated_layers.3.bn_node_u.running_var\", \"fc_layers.2.weight\", \"fc_layers.2.bias\". \n\tUnexpected key(s) in state_dict: \"readout_layer.layers.atom.lstm.weight_ih_l3\", \"readout_layer.layers.atom.lstm.weight_hh_l3\", \"readout_layer.layers.atom.lstm.bias_ih_l3\", \"readout_layer.layers.atom.lstm.bias_hh_l3\", \"readout_layer.layers.atom.lstm.weight_ih_l4\", \"readout_layer.layers.atom.lstm.weight_hh_l4\", \"readout_layer.layers.atom.lstm.bias_ih_l4\", \"readout_layer.layers.atom.lstm.bias_hh_l4\", \"readout_layer.layers.bond.lstm.weight_ih_l3\", \"readout_layer.layers.bond.lstm.weight_hh_l3\", \"readout_layer.layers.bond.lstm.bias_ih_l3\", \"readout_layer.layers.bond.lstm.bias_hh_l3\", \"readout_layer.layers.bond.lstm.weight_ih_l4\", \"readout_layer.layers.bond.lstm.weight_hh_l4\", \"readout_layer.layers.bond.lstm.bias_ih_l4\", \"readout_layer.layers.bond.lstm.bias_hh_l4\", \"fc_layers.6.weight\", \"fc_layers.6.bias\", \"fc_layers.1.weight\", \"fc_layers.1.bias\", \"fc_layers.1.running_mean\", \"fc_layers.1.running_var\", \"fc_layers.1.num_batches_tracked\", \"fc_layers.3.weight\", \"fc_layers.3.bias\", \"fc_layers.4.running_mean\", \"fc_layers.4.running_var\", \"fc_layers.4.num_batches_tracked\". \n\tsize mismatch for gated_layers.0.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 24]) from checkpoint, the shape in current model is torch.Size([192, 24]).\n\tsize mismatch for gated_layers.0.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.0.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.0.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.1.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.1.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.A.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.B.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.C.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.D.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.E.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.F.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.G.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.H.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n\tsize mismatch for gated_layers.2.I.fc_layers.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_h.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_e.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for gated_layers.2.bn_node_u.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l0: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.atom.lstm.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l0: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for readout_layer.layers.bond.lstm.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for fc_layers.0.weight: copying a param with shape torch.Size([32, 320]) from checkpoint, the shape in current model is torch.Size([384, 960]).\n\tsize mismatch for fc_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for fc_layers.4.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1, 192]).\n\tsize mismatch for fc_layers.4.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "\n",
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=dict_ret[\"embedding_size\"],\n",
    "    gated_num_layers=dict_ret[\"gated_num_layers\"],\n",
    "    gated_hidden_size=dict_ret[\"gated_hidden_size\"],\n",
    "    gated_activation=dict_ret[\"gated_activation\"],\n",
    "    gated_dropout=float(dict_ret[\"gated_dropout\"]),\n",
    "    gated_graph_norm=int(dict_ret[\"gated_graph_norm\"]),\n",
    "    gated_batch_norm=int(dict_ret[\"gated_batch_norm\"]),\n",
    "    gated_residual=dict_ret[\"gated_residual\"],\n",
    "    gated_num_fc_layers=dict_ret[\"gated_num_fc_layers\"],\n",
    "    fc_num_layers=dict_ret[\"fc_layers\"],\n",
    "    fc_hidden_size=dict_ret[\"fc_hidden_size\"],\n",
    "    fc_activation=dict_ret[\"fc_activation\"],\n",
    "    fc_dropout=float(dict_ret[\"fc_dropout\"]),\n",
    "    fc_batch_norm=int(dict_ret[\"fc_batch_norm\"]),\n",
    "    num_lstm_iters=dict_ret[\"num_lstm_iters\"],\n",
    "    num_lstm_layers=dict_ret[\"num_lstm_layers\"],\n",
    "    conv=\"GatedGCNConv\",\n",
    ")\n",
    "\n",
    "print(\"-\" * 20 + \"now disabling gradients\" + \"-\" * 20)\n",
    "model.gated_layers.requires_grad_(False)\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"checkpoint.pkl\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24432/2660373937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=dict_ret[\"embedding_size\"],\n",
    "    gated_num_layers=dict_ret[\"gated_num_layers\"],\n",
    "    gated_hidden_size=dict_ret[\"gated_hidden_size\"],\n",
    "    gated_activation=dict_ret[\"gated_activation\"],\n",
    "    gated_dropout=float(dict_ret[\"gated_dropout\"]),\n",
    "    gated_graph_norm=int(dict_ret[\"gated_graph_norm\"]),\n",
    "    gated_batch_norm=int(dict_ret[\"gated_batch_norm\"]),\n",
    "    gated_residual=dict_ret[\"gated_residual\"],\n",
    "    gated_num_fc_layers=dict_ret[\"gated_num_fc_layers\"],\n",
    "    fc_num_layers=dict_ret[\"fc_layers\"],\n",
    "    fc_hidden_size=dict_ret[\"fc_hidden_size\"],\n",
    "    fc_activation=dict_ret[\"fc_activation\"],\n",
    "    fc_dropout=float(dict_ret[\"fc_dropout\"]),\n",
    "    fc_batch_norm=int(dict_ret[\"fc_batch_norm\"]),\n",
    "    num_lstm_iters=dict_ret[\"num_lstm_iters\"],\n",
    "    num_lstm_layers=dict_ret[\"num_lstm_layers\"],\n",
    "    conv=\"GatedGCNConv\",\n",
    ")\n",
    "\n",
    "from os.path import expanduser\n",
    "\n",
    "home = expanduser(\"~\")\n",
    "model_ref = home + \"/Documents/Dataset/mg/\"\n",
    "\n",
    "# checkpoint = torch.load(model_ref + \"checkpoint.pkl\")\n",
    "# model.load_state_dict(checkpoint[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "path_mg_data = \"/home/santiagovargas/Documents/Dataset/mg_dataset/\"\n",
    "path_json = path_mg_data + \"20220613_reaction_data.json\"\n",
    "mg_df = pd.read_json(path_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "number of rxn failed: 141\n",
      "number of reactions with two products: 1326\n",
      "number of reactions with three products: 141\n"
     ]
    }
   ],
   "source": [
    "from bondnet.core.molwrapper import create_wrapper_mol_from_atoms_and_bonds\n",
    "from bondnet.core.reaction import Reaction\n",
    "\n",
    "error = 0\n",
    "two_product_count = 0\n",
    "three_prouct_count = 0\n",
    "\n",
    "for index, row in mg_df.iterrows():\n",
    "    # handle reactant\n",
    "    species = [i[\"name\"] for i in row[\"reactant_molecule_graph\"][\"molecule\"][\"sites\"]]\n",
    "    coords = [i[\"xyz\"] for i in row[\"reactant_molecule_graph\"][\"molecule\"][\"sites\"]]\n",
    "    bonds = row[\"reactant_bonds\"]\n",
    "    charge = row[\"charge\"]\n",
    "\n",
    "    reactant = create_wrapper_mol_from_atoms_and_bonds(\n",
    "        species, coords, bonds, charge=charge\n",
    "    )\n",
    "    reactant_list = [reactant]\n",
    "\n",
    "    # handle products\n",
    "    # check subgraphs first\n",
    "    product_list = []\n",
    "    num_nodes = 0\n",
    "    for i in row[\"composition\"].items():\n",
    "        num_nodes += int(i[-1])\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from([int(i) for i in range(num_nodes)])\n",
    "    for i in row[\"product_bonds\"]:\n",
    "        G.add_edge(i[0], i[1])\n",
    "    sub_graphs = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "\n",
    "    # still no handling for rxns A --> B + C +....\n",
    "    if len(sub_graphs) > 2:\n",
    "        three_prouct_count += 1\n",
    "    # handle A --> B + C\n",
    "    elif len(sub_graphs) == 2:\n",
    "        product_list = []\n",
    "        for sg in sub_graphs:\n",
    "            two_product_count += 1\n",
    "            nodes = list(sg.nodes())\n",
    "            bonds = list(sg.edges())\n",
    "            bond_reindex_list = []\n",
    "            species = [\n",
    "                row[\"product_molecule_graph\"][\"molecule\"][\"sites\"][sub_ind][\"name\"]\n",
    "                for sub_ind in list(sg.nodes())\n",
    "            ]\n",
    "            coords = [\n",
    "                row[\"product_molecule_graph\"][\"molecule\"][\"sites\"][sub_ind][\"xyz\"]\n",
    "                for sub_ind in list(sg.nodes())\n",
    "            ]\n",
    "            charge = row[\"charge\"]\n",
    "            for origin_bond_ind in row[\"product_bonds\"]:\n",
    "                check = any(item in origin_bond_ind for item in nodes)\n",
    "                if check:\n",
    "                    bond_orig = nodes.index(origin_bond_ind[0])\n",
    "                    bond_targ = nodes.index(origin_bond_ind[1])\n",
    "                    bond_reindex_list.append([bond_orig, bond_targ])\n",
    "\n",
    "                product = create_wrapper_mol_from_atoms_and_bonds(\n",
    "                    species, coords, bond_reindex_list, charge=charge\n",
    "                )\n",
    "            product_list.append(product)\n",
    "\n",
    "    # handle A --> B\n",
    "    else:\n",
    "        species = [\n",
    "            i[\"name\"] for i in row[\"product_molecule_graph\"][\"molecule\"][\"sites\"]\n",
    "        ]\n",
    "        coords = [i[\"xyz\"] for i in row[\"product_molecule_graph\"][\"molecule\"][\"sites\"]]\n",
    "        bonds = row[\"product_bonds\"]\n",
    "        charge = row[\"charge\"]\n",
    "        free_energy = row[\"product_free_energy\"]\n",
    "        product = create_wrapper_mol_from_atoms_and_bonds(\n",
    "            species=species, coords=coords, bonds=bonds, charge=charge\n",
    "        )\n",
    "        product_list = [product]\n",
    "    try:\n",
    "        rxn = Reaction(\n",
    "            reactants=reactant_list,\n",
    "            products=product_list,\n",
    "            broken_bond=row[\"bonds_broken\"],\n",
    "            free_energy=row[\"dE_barrier\"],\n",
    "            identifier=row[\"reaction_id\"],\n",
    "        )\n",
    "    except:\n",
    "        print(product_list)\n",
    "        error += 1\n",
    "print(\"number of rxn failed: \" + str(error))\n",
    "print(\"number of reactions with two products: \" + str(two_product_count))\n",
    "print(\"number of reactions with three products: \" + str(three_prouct_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# for i, sg in enumerate(sub_graphs):pass\n",
    "# print(list(sg.nodes()))\n",
    "# mg_df.iloc[1]['product_molecule_graph'][\"molecule\"][\"sites\"][18]\n",
    "# mg_df.iloc[1]['product_molecule_graph'][\"molecule\"][\"sites\"][2]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.5000, 0.1000],\n",
      "        [2.2000, 1.3000, 1.7000]])\n",
      "torch.Size([2, 3])\n",
      "tensor([1, 2])\n",
      "torch.Size([2])\n",
      "tensor(0.8393)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "yhat = torch.Tensor([[0.5, 1.5, 0.1], [2.2, 1.3, 1.7]])\n",
    "print(yhat)\n",
    "print(yhat.shape)\n",
    "# tensor([[0.5000, 1.5000, 0.1000],\n",
    "#         [2.2000, 1.3000, 1.7000]])\n",
    "\n",
    "y = torch.Tensor([1, 2]).to(torch.long)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "# tensor([1, 2])\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "cel = loss(input=yhat, target=y)\n",
    "print(cel)\n",
    "# tensor(0.8393)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aug 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time, wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "from torchmetrics import R2Score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from bondnet.model.metric import EarlyStopping\n",
    "from bondnet.data.dataset import ReactionNetworkDatasetGraphs\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "\n",
    "# from bondnet.scripts.create_label_file import read_input_files\n",
    "# from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.utils import seed_torch, pickle_dump, parse_settings\n",
    "from bondnet.model.training_utils import (\n",
    "    evaluate,\n",
    "    evaluate_classifier,\n",
    "    train,\n",
    "    train_classifier,\n",
    "    load_model,\n",
    "    evaluate_r2,\n",
    "    get_grapher,\n",
    ")\n",
    "\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the following settings:\n",
      "----------------------------------------\n",
      "Small Dataset?: False\n",
      "restore: True\n",
      "distributed: False\n",
      "on gpu: False\n",
      "num gpu: 1\n",
      "hyperparam save file: ./hyper.pkl\n",
      "dataset state dict: home/santiagovargas/Documents/Dataset/mg/dataset_state_dict.pkl\n",
      "model dir /home/santiagovargas/Documents/Dataset/mg/\n",
      "classifier False\n",
      "batch size: 256\n",
      "epochs: 100\n",
      "lr: 0.000100\n",
      "weight decay: 0.000\n",
      "early_stop: True\n",
      "scheduler: True\n",
      "transfer_epochs: 100\n",
      "transfer: False\n",
      "loss: False\n",
      "categories: 3\n",
      "embedding size: 24\n",
      "fc layers: 2\n",
      "fc hidden layer: [128, 64]\n",
      "gated layers: 3\n",
      "gated hidden layers: [64, 64, 64]\n",
      "num lstm iters: 6\n",
      "num lstm layer: 3\n",
      "gated fc layers: 2\n",
      "fc activation: ReLU\n",
      "fc batch norm: 0\n",
      "fc dropout: 0.00\n",
      "gated activation: ReLU\n",
      "gated dropout: 0.10\n",
      "gated batch norm: True\n",
      "gated graph norm: 0\n",
      "gated resid: True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best = 1e10\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "path_mg_data = \"../dataset/mg_dataset/\"\n",
    "dict_train = parse_settings(file=\"settings.txt\")\n",
    "path_mg_data = \"../../../dataset/mg_dataset/20220613_reaction_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on device: cpu\n"
     ]
    }
   ],
   "source": [
    "if dict_train[\"classifier\"]:\n",
    "    classif_categories = 5  # update this later\n",
    "else:\n",
    "    classif_categories = None\n",
    "\n",
    "if dict_train[\"on_gpu\"]:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dict_train[\"gpu\"] = device\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    dict_train[\"gpu\"] = \"cpu\"\n",
    "\n",
    "print(\"train on device: {}\".format(dict_train[\"gpu\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file from: ../dataset/mg_dataset/20220613_reaction_data.json\n",
      "rxn raw len: 3001\n",
      "Program finished in 14.417848569999478 seconds\n",
      ".............failures.............\n",
      "reactions len: 550\n",
      "valid ind len: 550\n",
      "bond break fail count: \t\t0\n",
      "default fail count: \t\t2451\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 1372\n",
      "labels: 550\n",
      "molecules: 1372\n",
      "constructing graphs & features....\n",
      "Valence of atom 0 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 0 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 1 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 1 is 5 which bigger than allowed max 4 . Stopping\n",
      "number of graphs valid: 1372\n",
      "number of graphs: 1372\n",
      "reading file from: ../dataset/mg_dataset/20220613_reaction_data.json\n",
      "rxn raw len: 3001\n",
      "Program finished in 14.515308740999899 seconds\n",
      ".............failures.............\n",
      "reactions len: 550\n",
      "valid ind len: 550\n",
      "bond break fail count: \t\t0\n",
      "default fail count: \t\t2451\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 1372\n",
      "labels: 550\n",
      "molecules: 1372\n",
      "constructing graphs & features....\n",
      "Valence of atom 0 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 0 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 1 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 1 is 5 which bigger than allowed max 4 . Stopping\n",
      "number of graphs valid: 1372\n",
      "number of graphs: 1372\n"
     ]
    }
   ],
   "source": [
    "path_mg_data = \"../dataset/mg_dataset/20220613_reaction_data.json\"\n",
    "\n",
    "dataset = ReactionNetworkDatasetGraphs(\n",
    "    grapher=get_grapher(),\n",
    "    file=path_mg_data,\n",
    "    out_file=\"./\",\n",
    "    target=\"ts\",\n",
    "    classifier=dict_train[\"classifier\"],\n",
    "    classif_categories=classif_categories,\n",
    "    debug=dict_train[\"debug\"],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset_transfer = ReactionNetworkDatasetGraphs(\n",
    "    grapher=get_grapher(),\n",
    "    file=path_mg_data,\n",
    "    out_file=\"./\",\n",
    "    target=\"diff\",\n",
    "    classifier=dict_train[\"classifier\"],\n",
    "    classif_categories=classif_categories,\n",
    "    debug=dict_train[\"debug\"],\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "for it, (bg, label) in enumerate(train_loader):\n",
    "    print(bg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, wandb\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork\n",
    "from bondnet.model.gated_reaction_network_classifier import (\n",
    "    GatedGCNReactionNetworkClassifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Training w/ transfer...\n",
      "Number of Trainable Model Params: 378177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [04:59<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Gated Layers....\n",
      "Number of Trainable Model Params: 282625\n",
      "# Epoch     Loss         TrainAcc        ValAcc        ValR2\n",
      "    0   5.838395e-01       5.86e-01   7.375593e-01   -0.05\n",
      "    1   5.697868e-01       5.87e-01   7.308374e-01   -0.05\n",
      "    2   5.829880e-01       5.71e-01   7.175438e-01   -0.04\n",
      "    3   5.574794e-01       5.58e-01   7.077865e-01   -0.00\n",
      "    4   5.375884e-01       5.28e-01   7.008233e-01   0.02\n",
      "    5   5.129869e-01       5.16e-01   6.963155e-01   0.04\n",
      "    6   5.009432e-01       5.09e-01   6.927217e-01   0.05\n",
      "    7   5.023253e-01       5.01e-01   6.913143e-01   0.05\n",
      "    8   4.861548e-01       4.94e-01   6.868426e-01   0.06\n",
      "    9   4.844654e-01       4.83e-01   6.779692e-01   0.07\n",
      "   10   4.862275e-01       4.80e-01   6.680047e-01   0.07\n",
      "   11   4.744842e-01       4.59e-01   6.621695e-01   0.07\n",
      "   12   4.487586e-01       4.59e-01   6.590375e-01   0.07\n",
      "   13   4.478369e-01       4.50e-01   6.578994e-01   0.07\n",
      "   14   4.340080e-01       4.44e-01   6.581209e-01   0.07\n",
      "   15   4.373392e-01       4.40e-01   6.618385e-01   0.07\n",
      "   16   4.463430e-01       4.31e-01   6.629799e-01   0.07\n",
      "   17   4.371514e-01       4.29e-01   6.618355e-01   0.07\n",
      "   18   4.256123e-01       4.26e-01   6.548281e-01   0.07\n",
      "   19   4.253395e-01       4.15e-01   6.479648e-01   0.07\n",
      "   20   4.218011e-01       4.09e-01   6.417127e-01   0.08\n",
      "   21   4.032951e-01       4.05e-01   6.377733e-01   0.08\n",
      "   22   3.995962e-01       4.02e-01   6.361310e-01   0.09\n",
      "   23   3.872430e-01       3.92e-01   6.347532e-01   0.09\n",
      "   24   3.888566e-01       3.88e-01   6.310512e-01   0.10\n",
      "   25   3.754388e-01       3.85e-01   6.260333e-01   0.10\n",
      "   26   3.781876e-01       3.84e-01   6.199250e-01   0.10\n",
      "   27   3.802067e-01       3.78e-01   6.131567e-01   0.11\n",
      "   28   3.722807e-01       3.74e-01   6.118084e-01   0.11\n",
      "   29   3.645576e-01       3.73e-01   6.126719e-01   0.11\n",
      "   30   3.853140e-01       3.69e-01   6.156015e-01   0.11\n",
      "   31   3.657052e-01       3.63e-01   6.171240e-01   0.11\n",
      "   32   3.599732e-01       3.60e-01   6.138751e-01   0.11\n",
      "   33   3.573481e-01       3.53e-01   6.080524e-01   0.11\n",
      "   34   3.530217e-01       3.52e-01   6.043926e-01   0.11\n",
      "   35   3.566010e-01       3.56e-01   6.012031e-01   0.11\n",
      "   36   3.537327e-01       3.47e-01   6.036009e-01   0.12\n",
      "   37   3.376990e-01       3.47e-01   6.083547e-01   0.12\n",
      "   38   3.612038e-01       3.42e-01   6.086566e-01   0.12\n",
      "   39   3.402812e-01       3.41e-01   6.048116e-01   0.12\n",
      "   40   3.403528e-01       3.36e-01   5.986138e-01   0.13\n",
      "   41   3.344969e-01       3.34e-01   5.941974e-01   0.13\n",
      "   42   3.245017e-01       3.29e-01   5.927786e-01   0.13\n",
      "   43   3.385617e-01       3.29e-01   5.958038e-01   0.13\n",
      "   44   3.260241e-01       3.23e-01   5.978029e-01   0.13\n",
      "   45   3.226236e-01       3.21e-01   5.963281e-01   0.13\n",
      "   46   3.167411e-01       3.19e-01   5.929149e-01   0.13\n",
      "   47   3.223284e-01       3.16e-01   5.872631e-01   0.13\n",
      "   48   3.062078e-01       3.14e-01   5.845769e-01   0.13\n",
      "   49   3.099862e-01       3.11e-01   5.849536e-01   0.13\n",
      "   50   3.183734e-01       3.14e-01   5.850297e-01   0.13\n",
      "   51   3.173677e-01       3.11e-01   5.860017e-01   0.13\n",
      "   52   3.214306e-01       3.09e-01   5.830245e-01   0.13\n",
      "   53   2.900479e-01       3.04e-01   5.817523e-01   0.13\n",
      "   54   3.078248e-01       3.05e-01   5.800795e-01   0.13\n",
      "   55   3.087905e-01       3.05e-01   5.796560e-01   0.13\n",
      "   56   3.115282e-01       2.97e-01   5.815539e-01   0.13\n",
      "   57   2.982634e-01       2.96e-01   5.812937e-01   0.13\n",
      "   58   3.021590e-01       2.99e-01   5.785795e-01   0.13\n",
      "   59   2.998863e-01       2.93e-01   5.756317e-01   0.13\n",
      "   60   2.974013e-01       2.95e-01   5.776396e-01   0.13\n",
      "   61   2.942022e-01       2.91e-01   5.824928e-01   0.13\n",
      "   62   2.954304e-01       2.93e-01   5.792802e-01   0.13\n",
      "   63   2.942028e-01       2.86e-01   5.756828e-01   0.13\n",
      "   64   2.888994e-01       2.87e-01   5.738564e-01   0.13\n",
      "   65   2.828143e-01       2.87e-01   5.783501e-01   0.13\n",
      "   66   2.889811e-01       2.83e-01   5.865941e-01   0.13\n",
      "   67   2.690466e-01       2.80e-01   5.823252e-01   0.13\n",
      "   68   2.851202e-01       2.82e-01   5.767246e-01   0.14\n",
      "   69   2.728924e-01       2.75e-01   5.733511e-01   0.14\n",
      "   70   2.668834e-01       2.76e-01   5.762049e-01   0.14\n",
      "   71   2.690835e-01       2.73e-01   5.792836e-01   0.13\n",
      "   72   2.625952e-01       2.71e-01   5.805435e-01   0.13\n",
      "   73   2.614257e-01       2.71e-01   5.818375e-01   0.13\n",
      "   74   2.656044e-01       2.68e-01   5.832277e-01   0.13\n",
      "   75   2.901386e-01       2.79e-01   5.827002e-01   0.13\n",
      "   76   2.712738e-01       2.68e-01   5.838720e-01   0.13\n",
      "   77   2.735066e-01       2.66e-01   5.866365e-01   0.13\n",
      "   78   2.761401e-01       2.70e-01   5.846247e-01   0.12\n",
      "   79   2.736868e-01       2.72e-01   5.808379e-01   0.12\n",
      "   80   2.691914e-01       2.70e-01   5.808950e-01   0.12\n",
      "   81   2.731666e-01       2.63e-01   5.813021e-01   0.13\n",
      "   82   2.662402e-01       2.65e-01   5.830745e-01   0.13\n",
      "   83   2.507610e-01       2.58e-01   5.820066e-01   0.13\n",
      "   84   2.800139e-01       2.70e-01   5.781380e-01   0.12\n",
      "   85   2.777054e-01       2.64e-01   5.826238e-01   0.12\n",
      "   86   2.638322e-01       2.65e-01   5.889512e-01   0.12\n",
      "   87   2.781243e-01       2.61e-01   5.874109e-01   0.12\n",
      "   88   2.678144e-01       2.62e-01   5.805439e-01   0.12\n",
      "   89   2.573538e-01       2.58e-01   5.851878e-01   0.12\n",
      "   90   2.580674e-01       2.57e-01   5.941451e-01   0.11\n",
      "   91   2.452001e-01       2.50e-01   5.935363e-01   0.12\n",
      "   92   2.488508e-01       2.52e-01   5.861177e-01   0.12\n",
      "   93   2.622976e-01       2.46e-01   5.837657e-01   0.12\n",
      "   94   2.586315e-01       2.49e-01   5.873582e-01   0.12\n",
      "   95   2.348961e-01       2.47e-01   5.861356e-01   0.12\n",
      "Epoch 00096: reducing learning rate of group 0 to 4.0000e-05.\n",
      "   96   2.458293e-01       2.47e-01   5.863371e-01   0.12\n",
      "   97   2.507009e-01       2.45e-01   5.869263e-01   0.11\n",
      "   98   2.477663e-01       2.46e-01   5.888829e-01   0.11\n",
      "   99   2.548995e-01       2.45e-01   5.911562e-01   0.11\n",
      "TestAcc: 5.824219e-01\n",
      "Time to Training: 265.8 seconds\n"
     ]
    }
   ],
   "source": [
    "dict_train[\"in_feats\"] = dataset.feature_size\n",
    "model, optimizer, optimizer_transfer = load_model(dict_train)\n",
    "model.to(device)\n",
    "\n",
    "trainset, valset, testset = train_validation_test_split(\n",
    "    dataset, validation=0.15, test=0.15\n",
    ")\n",
    "\n",
    "train_loader = DataLoaderReactionNetwork(\n",
    "    trainset, batch_size=dict_train[\"batch_size\"], shuffle=True\n",
    ")\n",
    "val_loader = DataLoaderReactionNetwork(valset, batch_size=len(valset), shuffle=False)\n",
    "test_loader = DataLoaderReactionNetwork(testset, batch_size=len(testset), shuffle=False)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.4, patience=25, verbose=True\n",
    ")\n",
    "stopper = EarlyStopping(patience=150)\n",
    "stopper_transfer = EarlyStopping(patience=150)\n",
    "\n",
    "if True:\n",
    "    trainset_transfer, valset_tranfer, _ = train_validation_test_split(\n",
    "        dataset_transfer, validation=0.15, test=0.01\n",
    "    )\n",
    "    dataset_transfer_loader = DataLoaderReactionNetwork(\n",
    "        trainset_transfer, batch_size=dict_train[\"batch_size\"], shuffle=True\n",
    "    )\n",
    "    dataset_transfer_loader_val = DataLoaderReactionNetwork(\n",
    "        valset_tranfer, batch_size=dict_train[\"batch_size\"], shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"Initiating Training w/ transfer...\")\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"Number of Trainable Model Params: {}\".format(params))\n",
    "\n",
    "    for epoch in tqdm(range(dict_train[\"transfer_epochs\"])):\n",
    "        if dict_train[\"classifier\"]:\n",
    "            _, _ = train_classifier(\n",
    "                model,\n",
    "                feature_names,\n",
    "                dataset_transfer_loader,\n",
    "                optimizer,\n",
    "                device=dict_train[\"gpu\"],\n",
    "                categories=classif_categories,\n",
    "            )\n",
    "            val_acc_transfer, f1_score = evaluate_classifier(\n",
    "                model,\n",
    "                feature_names,\n",
    "                dataset_transfer_loader_val,\n",
    "                device=dict_train[\"gpu\"],\n",
    "                categories=classif_categories,\n",
    "            )\n",
    "        else:\n",
    "            _, _ = train(\n",
    "                model,\n",
    "                feature_names,\n",
    "                dataset_transfer_loader,\n",
    "                optimizer,\n",
    "                device=dict_train[\"gpu\"],\n",
    "            )\n",
    "            val_acc_transfer = evaluate(\n",
    "                model,\n",
    "                feature_names,\n",
    "                dataset_transfer_loader_val,\n",
    "                device=dict_train[\"gpu\"],\n",
    "            )\n",
    "\n",
    "        if stopper_transfer.step(val_acc_transfer):\n",
    "            break\n",
    "\n",
    "    # freeze model layers but fc\n",
    "    model.gated_layers.requires_grad_(False)\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"Freezing Gated Layers....\")\n",
    "    print(\"Number of Trainable Model Params: {}\".format(params))\n",
    "\n",
    "t1 = time.time()\n",
    "# optimizer, loss function and metric function\n",
    "# main training loop\n",
    "if dict_train[\"classifier\"]:\n",
    "    print(\"# Epoch     Loss         TrainAcc        ValAcc        ValF1\")\n",
    "else:\n",
    "    print(\"# Epoch     Loss         TrainAcc        ValAcc        ValR2\")\n",
    "\n",
    "for epoch in range(dict_train[\"epochs\"]):\n",
    "    # train on training set\n",
    "    if dict_train[\"classifier\"]:\n",
    "        loss, train_acc = train_classifier(\n",
    "            model,\n",
    "            feature_names,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            device=dict_train[\"gpu\"],\n",
    "            categories=classif_categories,\n",
    "        )\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_acc, f1_score = evaluate_classifier(\n",
    "            model,\n",
    "            feature_names,\n",
    "            val_loader,\n",
    "            device=dict_train[\"gpu\"],\n",
    "            categories=classif_categories,\n",
    "        )\n",
    "\n",
    "        wandb.log({\"acc validation\": val_acc})\n",
    "        wandb.log({\"f1 validation\": f1_score})\n",
    "        print(\n",
    "            \"{:5d}   {:12.6e}   {:12.2e}   {:12.6e}   {:.2f}\".format(\n",
    "                epoch, loss, train_acc, val_acc, f1_score\n",
    "            )\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        loss, train_acc = train(\n",
    "            model, feature_names, train_loader, optimizer, dict_train[\"gpu\"]\n",
    "        )\n",
    "        # evaluate on validation set\n",
    "        val_acc = evaluate(model, feature_names, val_loader, dict_train[\"gpu\"])\n",
    "        val_r2 = evaluate_r2(model, feature_names, val_loader)\n",
    "\n",
    "        print(\n",
    "            \"{:5d}   {:12.6e}   {:12.2e}   {:12.6e}   {:.2f}\".format(\n",
    "                epoch, loss, train_acc, val_acc, val_r2\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # save checkpoint for best performing model\n",
    "    is_best = val_acc < best\n",
    "    if is_best:\n",
    "        best = val_acc\n",
    "        torch.save(model.state_dict(), \"checkpoint.pkl\")\n",
    "\n",
    "    if dict_train[\"early_stop\"]:\n",
    "        if stopper.step(val_acc):\n",
    "            pickle_dump(\n",
    "                best, dict_train[\"save_hyper_params\"]\n",
    "            )  # save results for hyperparam tune\n",
    "            break\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "checkpoint = torch.load(\"checkpoint.pkl\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "if dict_train[\"classifier\"]:\n",
    "    test_acc, test_f1 = evaluate_classifier(\n",
    "        model,\n",
    "        feature_names,\n",
    "        test_loader,\n",
    "        device=dict_train[\"gpu\"],\n",
    "        categories=classif_categories,\n",
    "    )\n",
    "    print(\"Test Acc: {:12.6e}\".format(test_acc))\n",
    "    print(\"Test F1: {:12.6e}\".format(test_f1))\n",
    "\n",
    "\n",
    "else:\n",
    "    test_acc = evaluate(model, feature_names, test_loader)\n",
    "    print(\"TestAcc: {:12.6e}\".format(test_acc))\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time to Training: {:5.1f} seconds\".format(float(t2 - t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, wandb\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchmetrics import F1Score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork\n",
    "from bondnet.model.gated_reaction_network_classifier import (\n",
    "    GatedGCNReactionNetworkClassifier,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import time, wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "from torchmetrics import R2Score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from bondnet.model.metric import EarlyStopping\n",
    "from bondnet.data.dataset import ReactionNetworkDatasetGraphs\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.featurizer import (\n",
    "    AtomFeaturizerGraph,\n",
    "    BondAsNodeGraphFeaturizer,\n",
    "    GlobalFeaturizerGraph,\n",
    ")\n",
    "from bondnet.data.grapher import (\n",
    "    HeteroCompleteGraphFromDGLAndPandas,\n",
    ")\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "\n",
    "# from bondnet.scripts.create_label_file import read_input_files\n",
    "# from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.utils import seed_torch, pickle_dump, parse_settings\n",
    "from bondnet.model.training_utils import (\n",
    "    evaluate,\n",
    "    evaluate_classifier,\n",
    "    train,\n",
    "    train_classifier,\n",
    "    load_model,\n",
    ")\n",
    "\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the following settings:\n",
      "----------------------------------------\n",
      "Small Dataset?: False\n",
      "restore: True\n",
      "distributed: False\n",
      "on gpu: False\n",
      "num gpu: 1\n",
      "hyperparam save file: ./hyper.pkl\n",
      "dataset state dict: home/santiagovargas/Documents/Dataset/mg/dataset_state_dict.pkl\n",
      "model dir /home/santiagovargas/Documents/Dataset/mg/\n",
      "classifier False\n",
      "batch size: 256\n",
      "epochs: 500\n",
      "lr: 0.000100\n",
      "weight decay: 0.000\n",
      "early_stop: True\n",
      "scheduler: True\n",
      "transfer_epochs: 500\n",
      "transfer: True\n",
      "loss: False\n",
      "categories: 5\n",
      "embedding size: 24\n",
      "fc layers: 2\n",
      "fc hidden layer: [394, 128]\n",
      "gated layers: 3\n",
      "gated hidden layers: [64, 64, 64]\n",
      "num lstm iters: 6\n",
      "num lstm layer: 3\n",
      "gated fc layers: 2\n",
      "fc activation: ReLU\n",
      "fc batch norm: 0\n",
      "fc dropout: 0.00\n",
      "gated activation: ReLU\n",
      "gated dropout: 0.10\n",
      "gated batch norm: True\n",
      "gated graph norm: 0\n",
      "gated resid: True\n",
      "----------------------------------------\n",
      "reading file from: ../dataset/mg_dataset/20220613_reaction_data.json\n",
      "rxn raw len: 3001\n",
      "Program finished in 12.270933712000442 seconds\n",
      ".............failures.............\n",
      "reactions len: 550\n",
      "valid ind len: 550\n",
      "bond break fail count: \t\t0\n",
      "default fail count: \t\t2451\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 1372\n",
      "labels: 550\n",
      "molecules: 1372\n",
      "constructing graphs & features....\n",
      "Valence of atom 0 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 0 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 1 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 1 is 5 which bigger than allowed max 4 . Stopping\n",
      "number of graphs valid: 1372\n",
      "number of graphs: 1372\n",
      "reading file from: ../dataset/mg_dataset/20220613_reaction_data.json\n",
      "rxn raw len: 3001\n",
      "Program finished in 14.333720992999588 seconds\n",
      ".............failures.............\n",
      "reactions len: 550\n",
      "valid ind len: 550\n",
      "bond break fail count: \t\t0\n",
      "default fail count: \t\t2451\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 1372\n",
      "labels: 550\n",
      "molecules: 1372\n",
      "constructing graphs & features....\n",
      "Valence of atom 0 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 0 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 1 is 5 which bigger than allowed max 4 . Stopping\n",
      "Valence of atom 1 is 5 which bigger than allowed max 4 . Stopping\n",
      "number of graphs valid: 1372\n",
      "number of graphs: 1372\n"
     ]
    }
   ],
   "source": [
    "path_mg_data = \"../dataset/mg_dataset/20220613_reaction_data.json\"\n",
    "settings_file = \"./training_reg/2/settings.txt\"\n",
    "classif_categories = 5\n",
    "device = None\n",
    "\n",
    "dict_train = parse_settings(settings_file)\n",
    "\n",
    "if device == None:\n",
    "    if dict_train[\"on_gpu\"]:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        dict_train[\"gpu\"] = device\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        dict_train[\"gpu\"] = \"cpu\"\n",
    "else:\n",
    "    dict_train[\"gpu\"] = device\n",
    "\n",
    "dataset_transfer = ReactionNetworkDatasetGraphs(\n",
    "    grapher=get_grapher(),\n",
    "    file=path_mg_data,\n",
    "    out_file=\"./\",\n",
    "    target=\"diff\",\n",
    "    classifier=dict_train[\"classifier\"],\n",
    "    classif_categories=classif_categories,\n",
    "    debug=dict_train[\"debug\"],\n",
    "    device=dict_train[\"gpu\"],\n",
    ")\n",
    "\n",
    "dataset = ReactionNetworkDatasetGraphs(\n",
    "    grapher=get_grapher(),\n",
    "    file=path_mg_data,\n",
    "    out_file=\"./\",\n",
    "    target=\"ts\",\n",
    "    classifier=dict_train[\"classifier\"],\n",
    "    classif_categories=classif_categories,\n",
    "    debug=dict_train[\"debug\"],\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the following settings:\n",
      "----------------------------------------\n",
      "Small Dataset?: False\n",
      "restore: True\n",
      "distributed: False\n",
      "on gpu: False\n",
      "num gpu: 1\n",
      "hyperparam save file: ./hyper.pkl\n",
      "dataset state dict: home/santiagovargas/Documents/Dataset/mg/dataset_state_dict.pkl\n",
      "model dir /home/santiagovargas/Documents/Dataset/mg/\n",
      "classifier False\n",
      "batch size: 256\n",
      "epochs: 500\n",
      "lr: 0.000100\n",
      "weight decay: 0.000\n",
      "early_stop: True\n",
      "scheduler: True\n",
      "transfer_epochs: 500\n",
      "transfer: False\n",
      "loss: False\n",
      "categories: 5\n",
      "embedding size: 24\n",
      "fc layers: 2\n",
      "fc hidden layer: [128, 64]\n",
      "gated layers: 1\n",
      "gated hidden layers: [128]\n",
      "num lstm iters: 6\n",
      "num lstm layer: 3\n",
      "gated fc layers: 2\n",
      "fc activation: ReLU\n",
      "fc batch norm: 0\n",
      "fc dropout: 0.00\n",
      "gated activation: ReLU\n",
      "gated dropout: 0.20\n",
      "gated batch norm: True\n",
      "gated graph norm: 0\n",
      "gated resid: True\n",
      "----------------------------------------\n",
      "train on device: cpu\n",
      "# Epoch     Loss         TrainAcc        ValAcc        ValR2\n",
      "    0   7.077151e-01       6.97e-01   6.296959e-01   -0.02   -0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10733/4261265765.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             )\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10733/3218593084.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, nodes, data_loader, optimizer, device)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# here is the actual optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBackwardCFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FunctionBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionCtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_HookMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# The user should define either backward or vjp but never both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best = 1e10\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "# path_mg_data = \"../dataset/mg_dataset/\"\n",
    "dict_train = parse_settings(settings_file)\n",
    "path_mg_data = \"../../../dataset/mg_dataset/20220613_reaction_data.json\"\n",
    "\n",
    "if dict_train[\"classifier\"]:\n",
    "    classif_categories = 5  # update this later\n",
    "    # wandb.init(project=\"project_classification_test\")\n",
    "else:\n",
    "    classif_categories = None\n",
    "    # wandb.init(project=\"project_regression_test\")\n",
    "\n",
    "if device == None:\n",
    "    if dict_train[\"on_gpu\"]:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        dict_train[\"gpu\"] = device\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        dict_train[\"gpu\"] = \"cpu\"\n",
    "else:\n",
    "    dict_train[\"gpu\"] = device\n",
    "# wandb.config.update(dict_train)\n",
    "dict_train[\"transfer\"] = False\n",
    "\n",
    "print(\"train on device: {}\".format(dict_train[\"gpu\"]))\n",
    "if dataset == None:\n",
    "    pass\n",
    "\n",
    "dict_train[\"in_feats\"] = dataset.feature_size\n",
    "model, optimizer, optimizer_transfer = load_model(dict_train)\n",
    "model.to(device)\n",
    "\n",
    "trainset, valset, testset = train_validation_test_split(\n",
    "    dataset, validation=0.15, test=0.15\n",
    ")\n",
    "\n",
    "train_loader = DataLoaderReactionNetwork(\n",
    "    trainset, batch_size=dict_train[\"batch_size\"], shuffle=True\n",
    ")\n",
    "val_loader = DataLoaderReactionNetwork(valset, batch_size=len(valset), shuffle=False)\n",
    "test_loader = DataLoaderReactionNetwork(testset, batch_size=len(testset), shuffle=False)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.4, patience=30, verbose=True\n",
    ")\n",
    "scheduler_transfer = ReduceLROnPlateau(\n",
    "    optimizer_transfer, mode=\"min\", factor=0.4, patience=30, verbose=True\n",
    ")\n",
    "stopper = EarlyStopping(patience=150)\n",
    "stopper_transfer = EarlyStopping(patience=150)\n",
    "\n",
    "if dict_train[\"transfer\"]:\n",
    "    if dataset_transfer == None:\n",
    "        pass\n",
    "\n",
    "    trainset_transfer, valset_tranfer, _ = train_validation_test_split(\n",
    "        dataset_transfer, validation=0.15, test=0.01\n",
    "    )\n",
    "    dataset_transfer_loader = DataLoaderReactionNetwork(\n",
    "        trainset_transfer, batch_size=dict_train[\"batch_size\"], shuffle=True\n",
    "    )\n",
    "    dataset_transfer_loader_val = DataLoaderReactionNetwork(\n",
    "        valset_tranfer, batch_size=dict_train[\"batch_size\"], shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"Initiating Training w/ transfer...\")\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"Number of Trainable Model Params: {}\".format(params))\n",
    "\n",
    "    for epoch in tqdm(range(dict_train[\"transfer_epochs\"])):\n",
    "        if dict_train[\"classifier\"]:\n",
    "            loss_transfer, train_acc_transfer = train_classifier(\n",
    "                model,\n",
    "                feature_names,\n",
    "                dataset_transfer_loader,\n",
    "                optimizer_transfer,\n",
    "                device=dict_train[\"gpu\"],\n",
    "                categories=classif_categories,\n",
    "            )\n",
    "            val_acc_transfer, f1_score = evaluate_classifier(\n",
    "                model,\n",
    "                feature_names,\n",
    "                dataset_transfer_loader_val,\n",
    "                device=dict_train[\"gpu\"],\n",
    "                categories=classif_categories,\n",
    "            )\n",
    "            # wandb.log({\"transfer_val_acc\": val_acc_transfer})\n",
    "            # wandb.log({\"transfer_val_f1\": f1_score})\n",
    "            # wandb.log({\"loss_transfer\": loss_transfer})\n",
    "            # wandb.log({\"train_acc_transfer\": train_acc_transfer})\n",
    "\n",
    "        else:\n",
    "            loss_transfer, train_acc_transfer = train(\n",
    "                model,\n",
    "                feature_names,\n",
    "                dataset_transfer_loader,\n",
    "                optimizer_transfer,\n",
    "                device=dict_train[\"gpu\"],\n",
    "            )\n",
    "            val_acc_transfer = evaluate(\n",
    "                model,\n",
    "                feature_names,\n",
    "                dataset_transfer_loader_val,\n",
    "                device=dict_train[\"gpu\"],\n",
    "            )\n",
    "            # wandb.log({\"loss_transfer\": loss_transfer})\n",
    "            # wandb.log({\"train_acc_transfer\": train_acc_transfer})\n",
    "            # wandb.log({\"val_acc_transfer\": val_acc_transfer})\n",
    "\n",
    "        scheduler_transfer.step(val_acc_transfer)\n",
    "        if stopper_transfer.step(val_acc_transfer):\n",
    "            break\n",
    "\n",
    "    # freeze model layers but fc\n",
    "    model.gated_layers.requires_grad_(False)\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"Freezing Gated Layers....\")\n",
    "    print(\"Number of Trainable Model Params: {}\".format(params))\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "if dict_train[\"classifier\"]:\n",
    "    print(\"# Epoch     Loss         TrainAcc        ValAcc        ValF1\")\n",
    "else:\n",
    "    print(\"# Epoch     Loss         TrainAcc        ValAcc        ValR2\")\n",
    "\n",
    "for epoch in range(dict_train[\"epochs\"]):\n",
    "    # train on training set\n",
    "    if dict_train[\"classifier\"]:\n",
    "        loss, train_acc = train_classifier(\n",
    "            model,\n",
    "            feature_names,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            device=dict_train[\"gpu\"],\n",
    "            categories=classif_categories,\n",
    "        )\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_acc, f1_score = evaluate_classifier(\n",
    "            model,\n",
    "            feature_names,\n",
    "            val_loader,\n",
    "            device=dict_train[\"gpu\"],\n",
    "            categories=classif_categories,\n",
    "        )\n",
    "\n",
    "        # wandb.log({\"acc validation\": val_acc})\n",
    "        # wandb.log({\"f1 validation\": f1_score})\n",
    "        print(\n",
    "            \"{:5d}   {:12.6e}   {:12.2e}   {:12.6e}   {:.2f}\".format(\n",
    "                epoch, loss, train_acc, val_acc, f1_score\n",
    "            )\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        loss, train_acc = train(\n",
    "            model, feature_names, train_loader, optimizer, device=dict_train[\"gpu\"]\n",
    "        )\n",
    "        # evaluate on validation set\n",
    "        val_acc = evaluate(model, feature_names, val_loader, device=dict_train[\"gpu\"])\n",
    "        val_r2 = evaluate_r2(model, feature_names, val_loader, device=dict_train[\"gpu\"])\n",
    "\n",
    "        val_r2_test = evaluate_r2_new(\n",
    "            model, feature_names, val_loader, device=dict_train[\"gpu\"]\n",
    "        )\n",
    "        # wandb.log({\"loss\": loss})\n",
    "        # wandb.log({\"mae_val\": val_acc})\n",
    "        # wandb.log({\"r2_val\": val_r2})\n",
    "\n",
    "        print(\n",
    "            \"{:5d}   {:12.6e}   {:12.2e}   {:12.6e}   {:.2f}   {:.2f}\".format(\n",
    "                epoch, loss, train_acc, val_acc, val_r2, val_r2_test\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # save checkpoint for best performing model\n",
    "    is_best = val_acc < best\n",
    "    if is_best:\n",
    "        best = val_acc\n",
    "        torch.save(model.state_dict(), \"checkpoint.pkl\")\n",
    "\n",
    "    if dict_train[\"early_stop\"]:\n",
    "        if stopper.step(val_acc):\n",
    "            pickle_dump(\n",
    "                best, dict_train[\"save_hyper_params\"]\n",
    "            )  # save results for hyperparam tune\n",
    "            break\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "checkpoint = torch.load(\"checkpoint.pkl\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "if dict_train[\"classifier\"]:\n",
    "    test_acc, test_f1 = evaluate_classifier(\n",
    "        model,\n",
    "        feature_names,\n",
    "        test_loader,\n",
    "        device=dict_train[\"gpu\"],\n",
    "        categories=classif_categories,\n",
    "    )\n",
    "\n",
    "    # wandb.log({\"acc validation\": test_acc})\n",
    "    # wandb.log({\"f1 validation\": test_f1})\n",
    "    print(\"Test Acc: {:12.6e}\".format(test_acc))\n",
    "    print(\"Test F1: {:12.6e}\".format(test_f1))\n",
    "\n",
    "else:\n",
    "    test_acc = evaluate(model, feature_names, test_loader, device=dict_train[\"gpu\"])\n",
    "    # wandb.log({\"mae_test\": test_acc})\n",
    "    print(\"TestMAE: {:12.6e}\".format(test_acc))\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time to Training: {:5.1f} seconds\".format(float(t2 - t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_172245/4185683810.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# test_acc = evaluate(model, feature_names, test_loader, device = dict_train[\"gpu\"])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accuracy = 0.0\n",
    "    count = 0.0\n",
    "    for batched_graph, label in test_loader:\n",
    "        feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in feature_names}\n",
    "        target = label[\"value\"]\n",
    "        stdev = label[\"scaler_stdev\"]\n",
    "        pred = model(batched_graph, feats, label[\"reaction\"])\n",
    "        print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0249346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.7717934846878052, 10.435993194580078)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_np = pred.detach().numpy()\n",
    "target_np = target.detach().numpy()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(pred_np, target_np)\n",
    "print(np.min(target_np))\n",
    "min_val = np.min([np.min(pred_np), np.min(target_np)]) - 0.5\n",
    "max_val = np.max([np.max(pred_np), np.max(target_np)]) + 0.5\n",
    "\n",
    "plt.ylim(min_val, max_val)\n",
    "plt.xlim(min_val, max_val)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mapping - Aug 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 3, 2: 2, 3: 0, 4: 4}\n",
      "[3, 0, 2, 1, 4]\n",
      "{0: 1, 1: 3, 2: 2, 3: 0, 4: 4}\n",
      "[3, 0, 2, 1, 4]\n",
      "{0: 1, 1: 4, 2: 2, 3: 0, 4: 3}\n",
      "[3, 0, 2, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def mapping_to_list(mappings, mode=\"atom\"):\n",
    "    \"\"\"\n",
    "    Given a list of mappings from products to reactants, return a representation\n",
    "    (mapping expressed using a list) from reactants to products.\n",
    "\n",
    "    Note: !!!!\n",
    "        This works only for the case where there is only one item difference\n",
    "        between reactants and products.\n",
    "\n",
    "    Args:\n",
    "        mappings (list of dict): mappings from products to reactants\n",
    "        mode (str): `atom` or `bond`. If bond, the mapping for the broken bond is\n",
    "        created. The broken bond is assumed to be the last bond in the products\n",
    "        and it is mapped to the corresponding bond of the reactants.\n",
    "\n",
    "    Returns:\n",
    "        list: mapping from reactant to product. The reactant are ordered (w.r.t.\n",
    "        indices). For example, a return list like [2,0,1] means:\n",
    "        item 0 in reactants corresponds to item 2 in products;\n",
    "        item 1 in reactants corresponds to item 0 in products; and\n",
    "        item 2 in reactants corresponds to item 1 in products.\n",
    "\n",
    "    Example:\n",
    "        >>>mappings = [{0:1, 1:3}, {0:2, 1:0}]\n",
    "        >>>_mapping_as_list(mappings)\n",
    "        >>>[3,0,2,1]\n",
    "        >>>\n",
    "        >>>mappings = [{0:1, 1:3}, {0:2, 1:0}, {}]  # bond 4 not in products\n",
    "        >>>_mapping_as_list(mappings)\n",
    "        >>>[3,0,2,1,4]\n",
    "        >>>\n",
    "        >>>mappings = [{0:1, 1:4}, {0:2, 1:0}, {}]  # bond 3 not in products\n",
    "        >>>_mapping_as_list(mappings)\n",
    "        >>>[3,0,2,4,1]\n",
    "    \"\"\"\n",
    "\n",
    "    sizes = [len(mp) for mp in mappings]\n",
    "    accumulate = [i for i in itertools.accumulate(sizes)]\n",
    "    accumulate = [0] + accumulate[:-1]\n",
    "\n",
    "    # combined mapping from products to reactants\n",
    "    # items in the first mapping is simply copied\n",
    "    # item 0 in the second mapping has a key = len(mappings[0]) + key\n",
    "    # ...\n",
    "    combined_mapping = {}\n",
    "    for i, mp in enumerate(mappings):\n",
    "        for p, r in mp.items():\n",
    "            assert p < len(mp), \"product item not smaller than size\"\n",
    "            combined_mapping[p + accumulate[i]] = r\n",
    "\n",
    "    # determine the missing item (in reactant) for empty mapping\n",
    "    if mode == \"bond\":\n",
    "        existing = np.concatenate([list(mp.values()) for mp in mappings])\n",
    "        N = len(existing)\n",
    "        expected = range(N + 1)\n",
    "\n",
    "        for i in expected:\n",
    "            if i not in existing:\n",
    "                missing_item = i\n",
    "                break\n",
    "\n",
    "        # add the missing item as the last element (of products)\n",
    "        combined_mapping[N] = missing_item\n",
    "\n",
    "    # r2p mapping as a list, where the reactant item is indexed by the list index\n",
    "    mp_list = sorted(combined_mapping, key=lambda k: combined_mapping[k])\n",
    "    print(combined_mapping)\n",
    "    return mp_list\n",
    "\n",
    "\n",
    "mappings = [{0: 1, 1: 3}, {0: 2, 1: 0}]\n",
    "list_map1 = mapping_to_list(mappings, mode=\"bond\")\n",
    "print(list_map1)  # [3,0,2,1]\n",
    "\n",
    "mappings = [{0: 1, 1: 3}, {0: 2, 1: 0}, {}]  # bond 4 not in products\n",
    "list_map2 = mapping_to_list(mappings, mode=\"bond\")\n",
    "print(list_map2)  # [3,0,2,1,4]\n",
    "\n",
    "mappings = [{0: 1, 1: 4}, {0: 2, 1: 0}, {}]  # bond 3 not in products\n",
    "list_map3 = mapping_to_list(mappings, mode=\"bond\")\n",
    "print(list_map3)  # [3,0,2,4,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reaction graph - aug 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import dgl\n",
    "import copy\n",
    "\n",
    "path_mg_data = \"/home/santiagovargas/Documents/Dataset/mg_dataset/\"\n",
    "path_json = path_mg_data + \"20220613_reaction_data.json\"\n",
    "mg_df = pd.read_json(path_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 4), (2, 7), (2, 8), (2, 3), (3, 9), (3, 5), (4, 10), (4, 11), (5, 6), (0, 1), (1, 2), (1, 4), (2, 7), (2, 3), (2, 8), (3, 9), (3, 4), (3, 5), (4, 11), (4, 10), (5, 6)]\n",
      "unique reactant bonds: 10\n",
      "unique product bonds: 12\n",
      "unique total bonds: 12\n",
      "bonds broken: 0\n",
      "bonds formed: 2\n"
     ]
    }
   ],
   "source": [
    "row = mg_df.iloc[0]\n",
    "bonds_reactants = copy.deepcopy(row[\"reactant_bonds\"])  # orignal bonds needed\n",
    "bonds_products = copy.deepcopy(row[\"product_bonds\"])  # original bonds needed\n",
    "total_bonds = [tuple(bond) for bond in bonds_reactants]\n",
    "[total_bonds.append(tuple(i)) for i in bonds_products]\n",
    "print(total_bonds)\n",
    "total_bonds = list(set(total_bonds))\n",
    "\n",
    "print(\"unique reactant bonds: {}\".format(len(bonds_reactants)))\n",
    "print(\"unique product bonds: {}\".format(len(bonds_products)))\n",
    "print(\"unique total bonds: {}\".format(len(total_bonds)))\n",
    "print(\"bonds broken: {}\".format(len(row[\"bonds_broken\"])))\n",
    "print(\"bonds formed: {}\".format(len(row[\"bonds_formed\"])))\n",
    "\n",
    "num_bonds = len(total_bonds)\n",
    "num_atoms = int(\n",
    "    np.sum([v for k, v in row[\"composition\"].items()])\n",
    ")  # total number of nodes?\n",
    "\n",
    "a2b = []\n",
    "b2a = []\n",
    "if num_bonds == 0:\n",
    "    num_bonds = 1\n",
    "    a2b = [(0, 0)]\n",
    "    b2a = [(0, 0)]\n",
    "\n",
    "else:\n",
    "    a2b = []\n",
    "    b2a = []\n",
    "    for b in range(num_bonds):\n",
    "        u = total_bonds[b][0]\n",
    "        v = total_bonds[b][1]\n",
    "        b2a.extend([[b, u], [b, v]])\n",
    "        a2b.extend([[u, b], [v, b]])\n",
    "\n",
    "a2g = [(a, 0) for a in range(num_atoms)]  # these are the messy ones\n",
    "g2a = [(0, a) for a in range(num_atoms)]  # these are the messy ones\n",
    "b2g = [(b, 0) for b in range(num_bonds)]  # these are the messy ones\n",
    "g2b = [(0, b) for b in range(num_bonds)]  # these are the messy ones\n",
    "\n",
    "edges_dict = {\n",
    "    (\"atom\", \"a2b\", \"bond\"): a2b,\n",
    "    (\"bond\", \"b2a\", \"atom\"): b2a,\n",
    "    (\"atom\", \"a2g\", \"global\"): a2g,\n",
    "    (\"global\", \"g2a\", \"atom\"): g2a,\n",
    "    (\"bond\", \"b2g\", \"global\"): b2g,\n",
    "    (\"global\", \"g2b\", \"bond\"): g2b,\n",
    "}\n",
    "self_loop = True\n",
    "\n",
    "if self_loop:\n",
    "    a2a = [(i, i) for i in range(num_atoms)]  # atom to atom nodes no mystery\n",
    "    b2b = [(i, i) for i in range(num_bonds)]  # self to self\n",
    "    g2g = [(0, 0)]  # global to global\n",
    "    edges_dict.update(\n",
    "        {\n",
    "            (\"atom\", \"a2a\", \"atom\"): a2a,\n",
    "            (\"bond\", \"b2b\", \"bond\"): b2b,\n",
    "            (\"global\", \"g2g\", \"global\"): g2g,\n",
    "        }\n",
    "    )\n",
    "\n",
    "g = dgl.heterograph(edges_dict)\n",
    "# add name\n",
    "# g.mol_name = mol.id\n",
    "# if(mol.original_atom_ind!=None):\n",
    "#    g.atom_ind = mol.original_atom_ind\n",
    "# if(mol.original_bond_mapping != None):\n",
    "#    g.bond_ind = mol.original_bond_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_species_graph(row, classifier=False, target=\"ts\"):\n",
    "    \"\"\"\n",
    "    Takes a row and processes the products/reactants - entirely defined by graphs from row\n",
    "\n",
    "    Args:\n",
    "        row: the row (series) pandas object\n",
    "\n",
    "    Returns:\n",
    "        mol_list: a list of MolecularWrapper object(s) for product(s) or reactant\n",
    "    \"\"\"\n",
    "    fail = 0\n",
    "    rxn, reactant_list, product_list, bond_map = [], [], [], []\n",
    "    reactant_key = \"reactant\"\n",
    "    product_key = \"product\"\n",
    "    reverse_rxn = False\n",
    "    formed_len, broken_len = len(row[\"bonds_formed\"]), len(row[\"bonds_broken\"])\n",
    "    check_list_len = formed_len + broken_len\n",
    "\n",
    "    if check_list_len == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        if broken_len == 0 and formed_len == 1:\n",
    "            reverse_rxn = True\n",
    "            reactant_key = \"product\"\n",
    "            product_key = \"reactant\"\n",
    "\n",
    "    species_reactant = [\n",
    "        int_atom(i[\"name\"])\n",
    "        for i in row[reactant_key + \"_molecule_graph\"][\"molecule\"][\"sites\"]\n",
    "    ]\n",
    "    species_products_full = [\n",
    "        int_atom(i[\"name\"])\n",
    "        for i in row[product_key + \"_molecule_graph\"][\"molecule\"][\"sites\"]\n",
    "    ]\n",
    "    coords_reactant = [\n",
    "        i[\"xyz\"] for i in row[reactant_key + \"_molecule_graph\"][\"molecule\"][\"sites\"]\n",
    "    ]\n",
    "    coords_products_full = [\n",
    "        i[\"xyz\"] for i in row[product_key + \"_molecule_graph\"][\"molecule\"][\"sites\"]\n",
    "    ]\n",
    "\n",
    "    charge = row[\"charge\"]\n",
    "    id = str(row[reactant_key + \"_id\"])\n",
    "    free_energy = row[product_key + \"_free_energy\"]\n",
    "    bonds_reactant = row[reactant_key + \"_bonds\"]\n",
    "    bonds_products = row[product_key + \"_bonds\"]\n",
    "\n",
    "    # new\n",
    "    total_bonds = [tuple(bond) for bond in bonds_reactant]\n",
    "    [total_bonds.append(tuple(i)) for i in bonds_products]\n",
    "    total_bonds = list(set(total_bonds))\n",
    "    total_bonds = [list(bond) for bond in total_bonds]\n",
    "\n",
    "    num_nodes = 0\n",
    "    for i in row[\"composition\"].items():\n",
    "        num_nodes += int(i[-1])\n",
    "\n",
    "    # will need to update once we want to generalize to more\n",
    "    # than one reactant\n",
    "    reactant = create_wrapper_mol_from_atoms_and_bonds(\n",
    "        species_reactant,\n",
    "        coords_reactant,\n",
    "        bonds_reactant,\n",
    "        charge=charge,\n",
    "        free_energy=free_energy,\n",
    "        identifier=id,\n",
    "        original_atom_ind=[int(i) for i in range(num_nodes)],\n",
    "        original_bond_ind=[list(i) for i in row[reactant_key + \"_bonds\"]],\n",
    "    )\n",
    "    reactant.nonmetal_bonds = row[reactant_key + \"_bonds_nometal\"]\n",
    "    reactant_list.append(reactant)\n",
    "\n",
    "    # handle products\n",
    "    # check subgraphs first\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from([int(i) for i in range(num_nodes)])\n",
    "    for i in row[product_key + \"_bonds\"]:\n",
    "        G.add_edge(i[0], i[1])\n",
    "    sub_graphs = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "    id = str(row[product_key + \"_id\"])\n",
    "\n",
    "    # still no handling for rxns A --> B + C +....\n",
    "    if len(sub_graphs) > 2:\n",
    "        pass  # print(\"cannot handle three or more products\")\n",
    "    # handle A --> B + C\n",
    "    elif len(sub_graphs) == 2:\n",
    "        mapping, mol_prod = [], []\n",
    "        for ind_sg, sg in enumerate(sub_graphs):\n",
    "            dict_prod = {}\n",
    "            coords_products, species_products, bond_reindex_list = [], [], []\n",
    "            nodes = list(sg.nodes())\n",
    "            bonds = list(sg.edges())\n",
    "\n",
    "            # finds bonds mapped to subgraphs\n",
    "            for origin_bond_ind in row[product_key + \"_bonds\"]:\n",
    "                # check if root to edge is in node list for subgraph\n",
    "                check = any(item in origin_bond_ind for item in nodes)\n",
    "                if check:\n",
    "                    bond_orig = nodes.index(origin_bond_ind[0])\n",
    "                    bond_targ = nodes.index(origin_bond_ind[1])\n",
    "                    bond_reindex_list.append([bond_orig, bond_targ])\n",
    "                    # finds the index of these nodes in the reactant bonds\n",
    "                    try:\n",
    "                        original_bond_index = row[reactant_key + \"_bonds\"].index(\n",
    "                            [origin_bond_ind[0], origin_bond_ind[1]]\n",
    "                        )\n",
    "                        dict_prod[len(bond_reindex_list) - 1] = original_bond_index\n",
    "                    except:\n",
    "                        print(\"detected bond in prod. not in react.\")\n",
    "            bond_map.append(dict_prod)\n",
    "\n",
    "            for site in nodes:\n",
    "                species_products.append(\n",
    "                    int_atom(\n",
    "                        row[product_key + \"_molecule_graph\"][\"molecule\"][\"sites\"][site][\n",
    "                            \"name\"\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                coords_products.append(\n",
    "                    row[product_key + \"_molecule_graph\"][\"molecule\"][\"sites\"][site][\n",
    "                        \"xyz\"\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            # mapping_temp = {i: ind for i, ind in enumerate(nodes)}\n",
    "            mapping_temp = {i: 1 for i, ind in enumerate(nodes)}\n",
    "\n",
    "            mapping.append(mapping_temp)\n",
    "\n",
    "            product = create_wrapper_mol_from_atoms_and_bonds(\n",
    "                species_products,\n",
    "                coords_products,\n",
    "                bond_reindex_list,\n",
    "                charge=0,\n",
    "                free_energy=free_energy,\n",
    "                identifier=id + \"_\" + str(ind_sg),\n",
    "                original_atom_ind=nodes,\n",
    "                original_bond_ind=[list(bond) for bond in bonds],\n",
    "            )\n",
    "\n",
    "            non_metal_products = row[product_key + \"_bonds_nometal\"]\n",
    "            non_metal_filter = []\n",
    "            for bond_non_metal in non_metal_products:\n",
    "                if bond_non_metal[0] in nodes or bond_non_metal[1] in nodes:\n",
    "                    non_metal_filter.append(bond_non_metal)\n",
    "            product.nonmetal_bonds = non_metal_filter  # adds into non_metal\n",
    "            product_list.append(product)\n",
    "\n",
    "    else:\n",
    "        dict_temp, dict_prod = {}, {}\n",
    "\n",
    "        product = create_wrapper_mol_from_atoms_and_bonds(\n",
    "            species_products_full,\n",
    "            coords_products_full,\n",
    "            bonds_products,\n",
    "            charge=charge,\n",
    "            free_energy=free_energy,\n",
    "            identifier=id,\n",
    "        )\n",
    "        product.nonmetal_bonds = row[product_key + \"_bonds_nometal\"]\n",
    "\n",
    "        # set bond mapping for one reactant w/only one product\n",
    "        for ind, i in enumerate(list(product.bonds.keys())):\n",
    "            try:\n",
    "                key_index = list(reactant_list[0].bonds.keys()).index(i)\n",
    "                dict_prod[ind] = key_index\n",
    "            except:\n",
    "                pass\n",
    "        bond_map = [dict_prod]\n",
    "\n",
    "        for i in range(len(species_products_full)):\n",
    "            dict_temp[i] = i\n",
    "        mapping = [dict_temp]\n",
    "\n",
    "        product_list.append(product)\n",
    "\n",
    "    if fail == 0 and product_list != [] and reactant_list != 0:\n",
    "        id = [i for i in row[\"reaction_id\"].split(\"-\")]\n",
    "        id = int(id[0] + id[1] + id[2])\n",
    "        broken_bond = None\n",
    "\n",
    "        if reverse_rxn:\n",
    "            if row[\"bonds_formed\"] != []:\n",
    "                broken_bond = row[\"bonds_formed\"][0]\n",
    "        else:\n",
    "            if row[\"bonds_broken\"] != []:\n",
    "                broken_bond = row[\"bonds_broken\"][0]\n",
    "\n",
    "        reactant_key + \"_energy\"\n",
    "        product_key + \"_energy\"\n",
    "\n",
    "        if target == \"ts\":\n",
    "            value = row[\"transition_state_energy\"] - row[reactant_key + \"_energy\"]\n",
    "        else:\n",
    "            value = row[product_key + \"_energy\"] - row[reactant_key + \"_energy\"]\n",
    "\n",
    "        if classifier:\n",
    "            if value <= 0.04:\n",
    "                value = 0\n",
    "            elif value < 0.3 and value > 0.04:\n",
    "                value = 1\n",
    "            elif value < 0.7 and value > 0.3:\n",
    "                value = 2\n",
    "            elif value < 1.5 and value > 0.7:\n",
    "                value = 3\n",
    "            else:\n",
    "                value = 4\n",
    "\n",
    "        rxn = Reaction(\n",
    "            reactants=reactant_list,\n",
    "            products=product_list,\n",
    "            free_energy=value,\n",
    "            broken_bond=broken_bond,\n",
    "            identifier=id,\n",
    "        )\n",
    "\n",
    "        rxn.set_atom_mapping(mapping)\n",
    "        rxn._bond_mapping_by_int_index = bond_map\n",
    "\n",
    "    return rxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 26269.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "list_test = [10, 21, 21]\n",
    "for ind, i in tqdm(enumerate(list_test)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 21, 21]\n"
     ]
    }
   ],
   "source": [
    "list_test = [10, 21, 21]\n",
    "sorted(list_test)\n",
    "print(list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test = [\n",
    "    {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        2: 2,\n",
    "        3: 3,\n",
    "        4: 4,\n",
    "        5: 5,\n",
    "        6: 6,\n",
    "        7: 7,\n",
    "        8: 8,\n",
    "        9: 9,\n",
    "        10: 10,\n",
    "        11: 11,\n",
    "        12: 12,\n",
    "        13: 13,\n",
    "        14: 14,\n",
    "        15: 15,\n",
    "        16: 16,\n",
    "    },\n",
    "    {0: 17},\n",
    "    {0: 18, 1: 19},\n",
    "]\n",
    "dict_test[0].values()\n",
    "[list(i.values()) for i in dict_test]\n",
    "import numpy as np\n",
    "\n",
    "list(set(list(np.concatenate([list(i.values()) for i in dict_test]).flat)))\n",
    "# list_trial = [k for i, k in enumerate(dict_test[0].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "preds = torch.ones(10) + 1\n",
    "target = torch.zeros(10)\n",
    "weight = torch.ones(10)\n",
    "# weight = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "from torchmetrics import MeanAbsoluteError, MeanSquaredError\n",
    "from bondnet.model.metric import Metrics_WeightedMAE, Metrics_WeightedMSE\n",
    "\n",
    "mae = MeanAbsoluteError()\n",
    "mse = MeanSquaredError()\n",
    "wmae = Metrics_WeightedMAE()\n",
    "wmse = Metrics_WeightedMSE()\n",
    "\n",
    "# print(mae(preds, target))\n",
    "# print(wmae(preds, target, weight))\n",
    "# print(mse(preds, target))\n",
    "# print(torch.sqrt(wmse(preds, target, weight)))\n",
    "mae.update(preds, target)\n",
    "wmae.update(preds, target, weight)\n",
    "mse.update(preds, target)\n",
    "wmse.update(preds, target, weight)\n",
    "mae.update(preds, target)\n",
    "wmae.update(preds, target, weight)\n",
    "mse.update(preds, target)\n",
    "wmse.update(preds, target, weight)\n",
    "preds = torch.ones(10) + 2\n",
    "mae.update(preds, target)\n",
    "wmae.update(preds, target, weight)\n",
    "mse.update(preds, target)\n",
    "wmse.update(preds, target, weight)\n",
    "mae.update(preds, target)\n",
    "wmae.update(preds, target, weight)\n",
    "mse.update(preds, target)\n",
    "wmse.update(preds, target, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor(2.5000)\n",
      "tensor(6.5000)\n",
      "tensor(6.5000)\n"
     ]
    }
   ],
   "source": [
    "print(mae.compute())\n",
    "print(wmae.compute())\n",
    "print(mse.compute())\n",
    "print(wmse.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../dataset/qm_9_hydro_merged_3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11013, 51)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water_bonds\n",
      "reactant_bonds\n",
      "product_bonds\n",
      "bonds_broken\n",
      "bonds_formed\n",
      "combined_product_bonds_local\n",
      "combined_product_bonds_global\n",
      "reactant_bonds_nometal\n",
      "product_bonds_nometal\n",
      "product_bonds_no_metal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i) for i in df.columns if \"bonds\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"product_bonds_nometal\"] = df[\"combined_product_bonds_global\"]\n",
    "df[\"reactant_bonds_nometal\"] = df[\"reactant_bonds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite df\n",
    "df.to_json(\"../dataset/qm_9_hydro_merged_3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mg_complete = \"../dataset/mg_dataset/mg_qtaim_complete.json\"\n",
    "# read\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(file_mg_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mg_complete = \"../dataset/mg_dataset/merged_mg.json\"\n",
    "# read\n",
    "import pandas as pd\n",
    "\n",
    "df_merged = pd.read_json(file_mg_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_feat_atom_reactant_partial_spins\n",
      "extra_feat_atom_product_partial_spin\n",
      "extra_feat_atom_reactant_valence_electrons\n",
      "extra_feat_atom_product_valence_electrons\n",
      "extra_feat_atom_reactant_total_electrons\n",
      "extra_feat_atom_product_total_electrons\n",
      "extra_feat_atom_reactant_s_char\n",
      "extra_feat_atom_product_s_char\n",
      "extra_feat_atom_reactant_p_char\n",
      "extra_feat_atom_product_p_char\n",
      "extra_feat_atom_reactant_d_char\n",
      "extra_feat_atom_product_d_char\n",
      "extra_feat_atom_reactant_f_char\n",
      "extra_feat_atom_product_f_char\n",
      "extra_feat_atom_reactant_elec_occ\n",
      "extra_feat_atom_product_elec_occ\n",
      "extra_feat_bond_reactant_1_s\n",
      "extra_feat_bond_reactant_2_s\n",
      "extra_feat_bond_reactant_1_p\n",
      "extra_feat_bond_reactant_2_p\n",
      "extra_feat_bond_reactant_1_d\n",
      "extra_feat_bond_reactant_2_d\n",
      "extra_feat_bond_reactant_1_f\n",
      "extra_feat_bond_reactant_2_f\n",
      "extra_feat_bond_reactant_1_polar\n",
      "extra_feat_bond_reactant_2_polar\n",
      "extra_feat_bond_reactant_occ_nbo\n",
      "extra_feat_bond_reactant_indices_nbo\n",
      "extra_feat_bond_product_2_s\n",
      "extra_feat_bond_product_1_s\n",
      "extra_feat_bond_product_1_p\n",
      "extra_feat_bond_product_2_p\n",
      "extra_feat_bond_product_1_d\n",
      "extra_feat_bond_product_2_d\n",
      "extra_feat_bond_product_1_f\n",
      "extra_feat_bond_product_2_f\n",
      "extra_feat_bond_product_1_polar\n",
      "extra_feat_bond_product_2_polar\n",
      "extra_feat_bond_product_occ_nbo\n",
      "extra_feat_bond_product_indices_nbo\n",
      "extra_feat_atom_product_partial_charges_mulliken\n",
      "extra_feat_atom_product_partial_charges_resp\n",
      "extra_feat_atom_product_partial_charges_nbo\n",
      "extra_feat_atom_reactant_partial_charges_mulliken\n",
      "extra_feat_atom_reactant_partial_charges_resp\n",
      "extra_feat_atom_reactant_partial_charges_nbo\n",
      "extra_feat_atom_reactant_partial_spins1\n",
      "extra_feat_atom_product_partial_spins1\n",
      "extra_feat_atom_reactant_partial_spins2\n",
      "extra_feat_atom_product_partial_spins2\n"
     ]
    }
   ],
   "source": [
    "for i in df_merged.columns:\n",
    "    if \"extra_feat\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5183, 172)\n",
      "(5183, 110)\n",
      "(5183, 281)\n"
     ]
    }
   ],
   "source": [
    "df.reaction_id\n",
    "\n",
    "\n",
    "# merge df and df_merged on reaction_id\n",
    "df_merged_final = df_merged.merge(df, on=\"reaction_id\", how=\"left\")\n",
    "print(df.shape)\n",
    "print(df_merged.shape)\n",
    "print(df_merged_final.shape)\n",
    "# save to json\n",
    "df_merged_final.to_json(\"../dataset/mg_dataset/mg_qtaim_nbo_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_feat_atom_reactant_Lagrangian_K\n",
      "extra_feat_atom_product_Lagrangian_K\n",
      "extra_feat_atom_reactant_Hamiltonian_K\n",
      "extra_feat_atom_product_Hamiltonian_K\n",
      "extra_feat_atom_reactant_e_density\n",
      "extra_feat_atom_product_e_density\n",
      "extra_feat_atom_reactant_lap_e_density\n",
      "extra_feat_atom_product_lap_e_density\n",
      "extra_feat_atom_reactant_e_loc_func\n",
      "extra_feat_atom_product_e_loc_func\n",
      "extra_feat_atom_reactant_ave_loc_ion_E\n",
      "extra_feat_atom_product_ave_loc_ion_E\n",
      "extra_feat_atom_reactant_delta_g_promolecular\n",
      "extra_feat_atom_product_delta_g_promolecular\n",
      "extra_feat_atom_reactant_delta_g_hirsh\n",
      "extra_feat_atom_product_delta_g_hirsh\n",
      "extra_feat_atom_reactant_esp_nuc\n",
      "extra_feat_atom_product_esp_nuc\n",
      "extra_feat_atom_reactant_esp_e\n",
      "extra_feat_atom_product_esp_e\n",
      "extra_feat_atom_reactant_esp_total\n",
      "extra_feat_atom_product_esp_total\n",
      "extra_feat_atom_reactant_grad_norm\n",
      "extra_feat_atom_product_grad_norm\n",
      "extra_feat_atom_reactant_lap_norm\n",
      "extra_feat_atom_product_lap_norm\n",
      "extra_feat_atom_reactant_eig_hess\n",
      "extra_feat_atom_product_eig_hess\n",
      "extra_feat_atom_reactant_det_hessian\n",
      "extra_feat_atom_product_det_hessian\n",
      "extra_feat_atom_reactant_ellip_e_dens\n",
      "extra_feat_atom_product_ellip_e_dens\n",
      "extra_feat_atom_reactant_eta\n",
      "extra_feat_atom_product_eta\n",
      "extra_feat_bond_reactant_Lagrangian_K\n",
      "extra_feat_bond_product_Lagrangian_K\n",
      "extra_feat_bond_reactant_Hamiltonian_K\n",
      "extra_feat_bond_product_Hamiltonian_K\n",
      "extra_feat_bond_reactant_e_density\n",
      "extra_feat_bond_product_e_density\n",
      "extra_feat_bond_reactant_lap_e_density\n",
      "extra_feat_bond_product_lap_e_density\n",
      "extra_feat_bond_reactant_e_loc_func\n",
      "extra_feat_bond_product_e_loc_func\n",
      "extra_feat_bond_reactant_ave_loc_ion_E\n",
      "extra_feat_bond_product_ave_loc_ion_E\n",
      "extra_feat_bond_reactant_delta_g_promolecular\n",
      "extra_feat_bond_product_delta_g_promolecular\n",
      "extra_feat_bond_reactant_delta_g_hirsh\n",
      "extra_feat_bond_product_delta_g_hirsh\n",
      "extra_feat_bond_reactant_esp_nuc\n",
      "extra_feat_bond_product_esp_nuc\n",
      "extra_feat_bond_reactant_esp_e\n",
      "extra_feat_bond_product_esp_e\n",
      "extra_feat_bond_reactant_esp_total\n",
      "extra_feat_bond_product_esp_total\n",
      "extra_feat_bond_reactant_grad_norm\n",
      "extra_feat_bond_product_grad_norm\n",
      "extra_feat_bond_reactant_lap_norm\n",
      "extra_feat_bond_product_lap_norm\n",
      "extra_feat_bond_reactant_eig_hess\n",
      "extra_feat_bond_product_eig_hess\n",
      "extra_feat_bond_reactant_det_hessian\n",
      "extra_feat_bond_product_det_hessian\n",
      "extra_feat_bond_reactant_ellip_e_dens\n",
      "extra_feat_bond_product_ellip_e_dens\n",
      "extra_feat_bond_reactant_eta\n",
      "extra_feat_bond_product_eta\n",
      "extra_feat_bond_reactant_indices_qtaim\n",
      "extra_feat_bond_product_indices_qtaim\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    if \"extra_feat\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_new = \"../dataset/mg_dataset/20230512_mpreact_assoc.bson\"\n",
    "# read  bson\n",
    "import pandas as pd\n",
    "import bson\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charge</th>\n",
       "      <th>spin_multiplicity</th>\n",
       "      <th>natoms</th>\n",
       "      <th>nelements</th>\n",
       "      <th>nelectrons</th>\n",
       "      <th>reactant_energy</th>\n",
       "      <th>reactant_zpe</th>\n",
       "      <th>reactant_enthalpy</th>\n",
       "      <th>reactant_entropy</th>\n",
       "      <th>reactant_free_energy</th>\n",
       "      <th>...</th>\n",
       "      <th>transition_state_entropy</th>\n",
       "      <th>transition_state_free_energy</th>\n",
       "      <th>dE</th>\n",
       "      <th>dH</th>\n",
       "      <th>dS</th>\n",
       "      <th>dG</th>\n",
       "      <th>dE_barrier</th>\n",
       "      <th>dH_barrier</th>\n",
       "      <th>dS_barrier</th>\n",
       "      <th>dG_barrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15047.000000</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>1.504700e+04</td>\n",
       "      <td>1.504700e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.504700e+04</td>\n",
       "      <td>1.504700e+04</td>\n",
       "      <td>1.504700e+04</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>1.504700e+04</td>\n",
       "      <td>1.504700e+04</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>15047.000000</td>\n",
       "      <td>1.504700e+04</td>\n",
       "      <td>1.504700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.043796</td>\n",
       "      <td>1.196783</td>\n",
       "      <td>14.912208</td>\n",
       "      <td>3.575131</td>\n",
       "      <td>58.581312</td>\n",
       "      <td>-11196.633673</td>\n",
       "      <td>3.181394</td>\n",
       "      <td>0.245536</td>\n",
       "      <td>inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-6.301901e-01</td>\n",
       "      <td>-0.613021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952779</td>\n",
       "      <td>0.883258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.397580</td>\n",
       "      <td>4.883673</td>\n",
       "      <td>0.721704</td>\n",
       "      <td>19.484293</td>\n",
       "      <td>7046.375807</td>\n",
       "      <td>1.333851</td>\n",
       "      <td>0.071968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.190019e-01</td>\n",
       "      <td>0.895061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.059007</td>\n",
       "      <td>1.016635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-113168.550773</td>\n",
       "      <td>0.084645</td>\n",
       "      <td>0.092797</td>\n",
       "      <td>1.771552e-03</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>2.010049e-03</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.344472e+01</td>\n",
       "      <td>-13.279421</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.429906</td>\n",
       "      <td>-1.413948</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>-13444.118523</td>\n",
       "      <td>2.237596</td>\n",
       "      <td>0.190624</td>\n",
       "      <td>3.345651e-03</td>\n",
       "      <td>-1.344083e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.257862e-03</td>\n",
       "      <td>-1.343889e+04</td>\n",
       "      <td>-8.511468e-01</td>\n",
       "      <td>-0.838094</td>\n",
       "      <td>-1.119849e-04</td>\n",
       "      <td>-8.327398e-01</td>\n",
       "      <td>0.114530</td>\n",
       "      <td>0.088192</td>\n",
       "      <td>-1.664922e-04</td>\n",
       "      <td>1.175954e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>-9336.794756</td>\n",
       "      <td>3.169575</td>\n",
       "      <td>0.229997</td>\n",
       "      <td>3.680782e-03</td>\n",
       "      <td>-9.338185e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.560970e-03</td>\n",
       "      <td>-9.335129e+03</td>\n",
       "      <td>-2.587183e-01</td>\n",
       "      <td>-0.250633</td>\n",
       "      <td>-1.257527e-06</td>\n",
       "      <td>-2.324476e-01</td>\n",
       "      <td>0.436131</td>\n",
       "      <td>0.381927</td>\n",
       "      <td>-9.331718e-05</td>\n",
       "      <td>4.249753e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>-7754.792756</td>\n",
       "      <td>4.102638</td>\n",
       "      <td>0.290207</td>\n",
       "      <td>4.181841e-03</td>\n",
       "      <td>-7.753376e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.056934e-03</td>\n",
       "      <td>-7.753253e+03</td>\n",
       "      <td>-3.496975e-03</td>\n",
       "      <td>-0.002890</td>\n",
       "      <td>3.098286e-05</td>\n",
       "      <td>-2.477791e-03</td>\n",
       "      <td>1.627661</td>\n",
       "      <td>1.532002</td>\n",
       "      <td>-1.478678e-05</td>\n",
       "      <td>1.567521e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>-2095.977058</td>\n",
       "      <td>9.587126</td>\n",
       "      <td>0.609597</td>\n",
       "      <td>inf</td>\n",
       "      <td>-2.095837e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>-2.095727e+03</td>\n",
       "      <td>-3.265086e-09</td>\n",
       "      <td>0.211935</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>10.179329</td>\n",
       "      <td>9.940399</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             charge  spin_multiplicity        natoms     nelements  \\\n",
       "count  15047.000000       15047.000000  15047.000000  15047.000000   \n",
       "mean      -0.043796           1.196783     14.912208      3.575131   \n",
       "std        0.560339           0.397580      4.883673      0.721704   \n",
       "min       -3.000000           1.000000      3.000000      2.000000   \n",
       "25%        0.000000           1.000000     11.000000      3.000000   \n",
       "50%        0.000000           1.000000     14.000000      4.000000   \n",
       "75%        0.000000           1.000000     18.000000      4.000000   \n",
       "max        3.000000           2.000000     41.000000      7.000000   \n",
       "\n",
       "         nelectrons  reactant_energy  reactant_zpe  reactant_enthalpy  \\\n",
       "count  15047.000000     15047.000000  15047.000000       15047.000000   \n",
       "mean      58.581312    -11196.633673      3.181394           0.245536   \n",
       "std       19.484293      7046.375807      1.333851           0.071968   \n",
       "min       12.000000   -113168.550773      0.084645           0.092797   \n",
       "25%       46.000000    -13444.118523      2.237596           0.190624   \n",
       "50%       52.000000     -9336.794756      3.169575           0.229997   \n",
       "75%       74.000000     -7754.792756      4.102638           0.290207   \n",
       "max      167.000000     -2095.977058      9.587126           0.609597   \n",
       "\n",
       "       reactant_entropy  reactant_free_energy  ...  transition_state_entropy  \\\n",
       "count      1.504700e+04          1.504700e+04  ...              1.504700e+04   \n",
       "mean                inf                  -inf  ...                       inf   \n",
       "std                 NaN                   NaN  ...                       NaN   \n",
       "min        1.771552e-03                  -inf  ...              2.010049e-03   \n",
       "25%        3.345651e-03         -1.344083e+04  ...              3.257862e-03   \n",
       "50%        3.680782e-03         -9.338185e+03  ...              3.560970e-03   \n",
       "75%        4.181841e-03         -7.753376e+03  ...              4.056934e-03   \n",
       "max                 inf         -2.095837e+03  ...                       inf   \n",
       "\n",
       "       transition_state_free_energy            dE            dH            dS  \\\n",
       "count                  1.504700e+04  1.504700e+04  15047.000000  1.504700e+04   \n",
       "mean                           -inf -6.301901e-01     -0.613021           NaN   \n",
       "std                             NaN  9.190019e-01      0.895061           NaN   \n",
       "min                            -inf -1.344472e+01    -13.279421          -inf   \n",
       "25%                   -1.343889e+04 -8.511468e-01     -0.838094 -1.119849e-04   \n",
       "50%                   -9.335129e+03 -2.587183e-01     -0.250633 -1.257527e-06   \n",
       "75%                   -7.753253e+03 -3.496975e-03     -0.002890  3.098286e-05   \n",
       "max                   -2.095727e+03 -3.265086e-09      0.211935           inf   \n",
       "\n",
       "                 dG    dE_barrier    dH_barrier    dS_barrier    dG_barrier  \n",
       "count  1.504700e+04  15047.000000  15047.000000  1.504700e+04  1.504700e+04  \n",
       "mean            NaN      0.952779      0.883258           NaN           NaN  \n",
       "std             NaN      1.059007      1.016635           NaN           NaN  \n",
       "min            -inf     -1.429906     -1.413948          -inf          -inf  \n",
       "25%   -8.327398e-01      0.114530      0.088192 -1.664922e-04  1.175954e-01  \n",
       "50%   -2.324476e-01      0.436131      0.381927 -9.331718e-05  4.249753e-01  \n",
       "75%   -2.477791e-03      1.627661      1.532002 -1.478678e-05  1.567521e+00  \n",
       "max             inf     10.179329      9.940399           inf           inf  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_new, \"rb\") as f:\n",
    "    data = bson.decode_all(f.read())\n",
    "main_df = pd.DataFrame(data)\n",
    "main_df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type ObjectId is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3042488/2653192976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".bson\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\".json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ObjectId is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# save as json of the same name and location\n",
    "# main_df.to_json(file_new.replace(\".bson\",\".json\"))\n",
    "\n",
    "# convert to json without pandas\n",
    "import json\n",
    "\n",
    "with open(file_new, \"rb\") as f:\n",
    "    data = bson.decode_all(f.read())\n",
    "    with open(file_new.replace(\".bson\", \".json\"), \"w\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c205a9eb4435b0aa27aaf0e9c4340d2b9512e0cc8b49dbd290219ad3711c312f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('bondnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
